{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문\n",
    "> 순서도 따라서 어떻게 해야 되는지\n",
    "\n",
    "1. 날짜 뱉어내\n",
    "2. 날짜를 넘겨\n",
    "3. 트윗 검색 조건 설정해\n",
    "\n",
    "---\n",
    "\n",
    "이건 내가 가능하려나 싶은\n",
    "\n",
    "- getJsondata 안에서 바로 바로 읽어올 때마다 하는 방식은?\n",
    "- 체크포인트,,,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- 대충 해결------\n",
    "- HTTPError 429 : fakeuseragent 해결 가능한지 확인\n",
    "    - 일단 time.sleep(3) 정도면 트위터가 봐주는듯\n",
    "    - 애초에 여기 헤더에 있는 헤더가 랜덤으로 헤더 가져오고, 거의 fake useragent에 있는 애들이다. 굳이 건들지 않아도 될듯?\n",
    "\n",
    "-------- 해결 ㄴㄴ-----------\n",
    "\n",
    "- 제너레이터 만들어서 날짜 뱉어내고, 하루 단위로 실행하도록 만들기.\n",
    "- 날짜 너무 비효율적인디?\n",
    "- 제발 클래스로...\n",
    "- retry 데코레이터 ㅇㅇㅇ\n",
    "- getJsondata 안에서 바로 바로 읽어올 때마다 하는 방식은?\n",
    "- 체크포인트,,,\n",
    "\n",
    "- 함수 바꾼 부분 정리해/놓기!!!!!\n",
    "- 스태틱 메소드니까 상관 ㄴㄴㄴㄴㄴㄴ\n",
    "- logger 찍어야 하는디\n",
    "\n",
    "\n",
    "-------- adsp 끝나고 ----------\n",
    "\n",
    "\n",
    "- retry while문 구현 실패. 아마 패키지 자체가 tweet 가져오는 과정에서 뭔가 있는듯한데 어떻게 소스 확인해야할지 고민\n",
    "\n",
    "\n",
    "- 패키지 코드 다시 확인 : Tweet 객체 안에서 tqdm 찍게 못 바꾸나.\n",
    "    - 일단 지금까지 확인한 건 tweet 객체 생성을 위해 트위터 스크롤 다 내리는 방식인듯한디.\n",
    "    - 애초에 내가 확인하고 싶은 건 크롤링 진행 상황. 이게 오래 걸리는 건데 밑에서 tqdm 찍는 건 개 빨라서 굳이 의미 ㄴㄴ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in c:\\users\\sir95\\anaconda3\\envs\\cpu_env\\lib\\site-packages (0.0.11)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\sir95\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from GetOldTweets3) (4.5.1)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in c:\\users\\sir95\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\sir95\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install GOT3 package\n",
    "!pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import urllib\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False):\n",
    "    \"\"\"\n",
    "    Invoke an HTTP query to Twitter.\n",
    "    Should not be used as an API function. A static method.\n",
    "    \"\"\"\n",
    "    url = \"https://twitter.com/i/search/timeline?\"\n",
    "\n",
    "    if not tweetCriteria.topTweets:\n",
    "        url += \"f=tweets&\"\n",
    "\n",
    "    url += (\"vertical=news&q=%s&src=typd&%s\"\n",
    "            \"&include_available_features=1&include_entities=1&max_position=%s\"\n",
    "            \"&reset_error_state=false\")\n",
    "\n",
    "    urlGetData = ''\n",
    "\n",
    "    if hasattr(tweetCriteria, 'querySearch'):\n",
    "        urlGetData += tweetCriteria.querySearch\n",
    "\n",
    "    if hasattr(tweetCriteria, 'excludeWords'):\n",
    "        urlGetData += ' -'.join([''] + tweetCriteria.excludeWords)\n",
    "\n",
    "    if hasattr(tweetCriteria, 'username'):\n",
    "        if not hasattr(tweetCriteria.username, '__iter__'):\n",
    "            tweetCriteria.username = [tweetCriteria.username]\n",
    "\n",
    "        usernames_ = [u.lstrip('@') for u in tweetCriteria.username if u]\n",
    "        tweetCriteria.username = {u.lower() for u in usernames_ if u}\n",
    "\n",
    "        usernames = [' from:'+u for u in sorted(tweetCriteria.username)]\n",
    "        if usernames:\n",
    "            urlGetData += ' OR'.join(usernames)\n",
    "\n",
    "    if hasattr(tweetCriteria, 'within'):\n",
    "        if hasattr(tweetCriteria, 'near'):\n",
    "            urlGetData += ' near:\"%s\" within:%s' % (tweetCriteria.near, tweetCriteria.within)\n",
    "        elif hasattr(tweetCriteria, 'lat') and hasattr(tweetCriteria, 'lon'):\n",
    "            urlGetData += ' geocode:%f,%f,%s' % (tweetCriteria.lat, tweetCriteria.lon, tweetCriteria.within)\n",
    "\n",
    "    if hasattr(tweetCriteria, 'since'):\n",
    "        urlGetData += ' since:' + tweetCriteria.since\n",
    "\n",
    "    if hasattr(tweetCriteria, 'until'):\n",
    "        urlGetData += ' until:' + tweetCriteria.until\n",
    "\n",
    "    if hasattr(tweetCriteria, 'minReplies'):\n",
    "        urlGetData += ' min_replies:' + tweetCriteria.minReplies\n",
    "\n",
    "    if hasattr(tweetCriteria, 'minFaves'):\n",
    "        urlGetData += ' min_faves:' + tweetCriteria.minFaves\n",
    "\n",
    "    if hasattr(tweetCriteria, 'minRetweets'):\n",
    "        urlGetData += ' min_retweets:' + tweetCriteria.minRetweets\n",
    "\n",
    "    if hasattr(tweetCriteria, 'lang'):\n",
    "        urlLang = 'l=' + tweetCriteria.lang + '&'\n",
    "    else:\n",
    "        urlLang = ''\n",
    "    url = url % (urllib.parse.quote(urlGetData.strip()), urlLang, urllib.parse.quote(refreshCursor))\n",
    "    useragent = useragent or TweetManager.user_agents[0]\n",
    "\n",
    "    headers = [\n",
    "        ('Host', \"twitter.com\"),\n",
    "        ('User-Agent', useragent),\n",
    "        ('Accept', \"application/json, text/javascript, */*; q=0.01\"),\n",
    "        ('Accept-Language', \"en-US,en;q=0.5\"),\n",
    "        ('X-Requested-With', \"XMLHttpRequest\"),\n",
    "        ('Referer', url),\n",
    "        ('Connection', \"keep-alive\")\n",
    "    ]\n",
    "\n",
    "    if proxy:\n",
    "        opener = urllib.request.build_opener(urllib.request.ProxyHandler({'http': proxy, 'https': proxy}), urllib.request.HTTPCookieProcessor(cookieJar))\n",
    "    else:\n",
    "        opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookieJar))\n",
    "    opener.addheaders = headers\n",
    "\n",
    "    if debug:\n",
    "        print(url)\n",
    "        # print('\\n'.join(h[0]+': '+h[1] for h in headers))\n",
    "\n",
    "    # HTTP Request 429 : 타임 슬립 줘보자\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        response = opener.open(url)\n",
    "        jsonResponse = response.read()\n",
    "\n",
    "    except TimeoutError as e:\n",
    "        print(\"Timeout error\")\n",
    "        print('sleep 30')\n",
    "        time.sleep(30)\n",
    "\n",
    "        #이 부분 나중에 retry로 진행하기\n",
    "        try:\n",
    "            response = opener.open(url)\n",
    "            jsonResponse = response.read()\n",
    "        except TimeoutError as e:\n",
    "            print(\"Timeout Error again.\")\n",
    "            print(\"Pass Data!!!!!!!!!\")\n",
    "            pass\n",
    "\n",
    "#     count = 0\n",
    "#     while True:\n",
    "#         try:\n",
    "#             response = opener.open(url)\n",
    "#             jsonResponse = response.read()\n",
    "        \n",
    "#             # 완료시 break 에러시 except 문 실행.\n",
    "#             break\n",
    "            \n",
    "#         except TimeOutError as e:\n",
    "#             print(\"Timeout error\")\n",
    "#             count+=1\n",
    "#             if count >=3:\n",
    "#                 break\n",
    "#             time.sleep(30)\n",
    "\n",
    "#     if count >=3:\n",
    "#         continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occured during an HTTP request:\", str(e))\n",
    "        print(\"Error URL:\", url)\n",
    "        print(\"Try to open in browser: https://twitter.com/search?q=%s&src=typd\" % urllib.parse.quote(urlGetData))\n",
    "\n",
    "        # 이 부분 나중에 확인하기\n",
    "        print(\"sleep 30!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        pass\n",
    "        # sys.exit()\n",
    "        \n",
    "\n",
    "    try:\n",
    "        s_json = jsonResponse.decode()\n",
    "    except:\n",
    "        print(\"Invalid response from Twitter\")\n",
    "        print(\"Error URL:\", url)\n",
    "        pass\n",
    "        # sys.exit()\n",
    "    else:\n",
    "        try:\n",
    "            dataJson = json.loads(s_json)\n",
    "        except:\n",
    "            print(\"Error parsing JSON: %s\" % s_json)\n",
    "            print(\"Error URL:\", url)\n",
    "        pass\n",
    "        # sys.exit()\n",
    "\n",
    "#     if debug:\n",
    "#         print(s_json)\n",
    "#         print(\"---\\n\")\n",
    "\n",
    "    return dataJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 다시 입력해야 할 때 에러 발생시키자.\n",
    "class NotValidEndDateError(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__('마지막 검색 날짜를 다시 설정하십시오.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GetOldTweets3 패키지의 setUntil 메소드는 마지막 날짜 포함하지 않으므로, 주의.\n",
    "def set_crawl_date(start_date, end_date):\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(str(start_date), \"%Y%m%d\")\n",
    "    end_date = datetime.datetime.strptime(str(end_date), \"%Y%m%d\") - datetime.timedelta(days=1)\n",
    "    \n",
    "    if end_date == start_date:\n",
    "        raise NotValidEndDateError\n",
    "    \n",
    "    else:   \n",
    "        print(\"트윗 수집 날짜 설정: {0}부터 {1}까지\".format(start_date, end_date))    \n",
    "        return start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_tweets(start_date, end_date, debug=False):    \n",
    "    got.manager.TweetManager.getJsonResponse = getJsonResponse # 함수에 이 부분 넣어주고\n",
    "    \n",
    "    print(\"========== 트윗 수집 시작: {0} ~ {1} ==========\".format(start_date, end_date))\n",
    "    start_time = time.time()\n",
    "    tweet_criteria = got.manager.TweetCriteria().setQuerySearch('Elon Musk')\\\n",
    "                                                .setSince(start_date)\\\n",
    "                                                .setUntil(end_date)\\\n",
    "                                                .setLang('en')\n",
    "    tweets = got.manager.TweetManager.getTweets(tweet_criteria, debug=debug)\n",
    "    \n",
    "    elapsed_time = time.time()-start_time\n",
    "    \n",
    "    print(\"수집 완료 : {}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n",
    "    print(\"총 수집 트윗 개수 : {0}\".format(len(tweets)))\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(tweet_data):\n",
    "    results = []\n",
    "    for tweet in tqdm(tweet_data):\n",
    "        results.append({'url': tweet.permalink,\n",
    "                        'date': tweet.date,\n",
    "                        'text': tweet.text,\n",
    "                        'user': tweet.username,\n",
    "                        'mentions': tweet.mentions,\n",
    "                        'retweets': tweet.retweets,\n",
    "                        'favorites': tweet.favorites,\n",
    "                        'hashtags': tweet.hashtags})\n",
    "        \n",
    "    return results        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets(tweet_lists):\n",
    "    base_file_dir = \"tweets\"\n",
    "\n",
    "    if not os.path.exists(base_file_dir):\n",
    "        os.makedirs(base_file_dir)\n",
    "        \n",
    "    with open(f\"{base_file_dir}/tweets_{crawl_start}_{crawl_end}.csv\", \"a\", -1, encoding=\"utf-8\") as f:    \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['url', 'date', 'text', 'user', 'mentions', 'retweets', 'favorites', 'hashtags'])        \n",
    "        for tweet_list in tqdm(tweet_lists):\n",
    "            writer.writerow(list(tweet_list.values()))\n",
    "            \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트윗 수집 날짜 설정: 2020-02-01 00:00:00부터 2020-02-02 00:00:00까지\n"
     ]
    }
   ],
   "source": [
    "crawl_start, crawl_end = set_crawl_date(20200201, 20200203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 트윗 수집 시작: 2020-02-01 ~ 2020-02-02 ==========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e4d276fc0ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweet_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrawl_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawl_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrawl_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0f158ceef22b>\u001b[0m in \u001b[0;36mcrawl_tweets\u001b[1;34m(start_date, end_date, debug)\u001b[0m\n\u001b[0;32m      8\u001b[0m                                                 \u001b[1;33m.\u001b[0m\u001b[0msetUntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                 \u001b[1;33m.\u001b[0m\u001b[0msetLang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweetManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_criteria\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\u001b[0m in \u001b[0;36mgetTweets\u001b[1;34m(tweetCriteria, receiveBuffer, bufferLength, proxy, debug)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mactive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mactive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetJsonResponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweetCriteria\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefreshCursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcookieJar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'items_html'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-3a031ec3a92e>\u001b[0m in \u001b[0;36mgetJsonResponse\u001b[1;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mjsonResponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1362\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweet_results = crawl_tweets(crawl_start, crawl_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_results_lists = get_results(tweet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tweets(tweet_results_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트윗 수집 날짜 설정: 2020-06-01 00:00:00부터 2020-06-02 00:00:00까지\n"
     ]
    }
   ],
   "source": [
    "crawl_start, crawl_end = set_crawl_date(20200601, 20200603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 트윗 수집 시작: 2020-06-01 ~ 2020-06-02 ==========\n"
     ]
    }
   ],
   "source": [
    "tweet_results = crawl_tweets(crawl_start, crawl_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_results_lists = get_results(tweet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tweets(tweet_results_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retry 질문..\n",
    "\n",
    "도대체 어떻게 쓰는거니 ㅠㅅㅠ 머리야 생각을해..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retry(total_try_cnt=5, sleep_in_sec=5, retryable_exceptions=(TimeoutError)):\n",
    "#     def decorator(getJsonResponse):\n",
    "#         @functools.wraps(getJsonResponse)\n",
    "#         def wrapper(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False):\n",
    "#             for cnt in range(total_try_cnt):\n",
    "#                 logger.info(f\"trying {func.__name__}() [{cnt+1}/{total_try_cnt}]\")\n",
    "\n",
    "#                 try:\n",
    "#                     result = func(*args, **kwargs)\n",
    "#                     logger.info(f\"in retry(), {func.__name__}() returned '{result}'\")\n",
    "\n",
    "#                     if result: \n",
    "#                         return result\n",
    "#                 except retryable_exceptions as e:\n",
    "#                     logger.info(f\"in retry(), {func.__name__}() raised retryable exception '{e}'\")\n",
    "#                     pass\n",
    "#                 except Exception as e:\n",
    "#                     logger.info(f\"in retry(), {func.__name__}() raised {e}\")\n",
    "#                     print(str(e))\n",
    "#                     pass \n",
    "#                     # raise e\n",
    "                    \n",
    "\n",
    "#                 time.sleep(sleep_in_sec)\n",
    "#             logger.info(f\"{func.__name__} finally has been failed\")\n",
    "#         return wrapper\n",
    "#     return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameError: name 'tweetCriteria' is not defined\n",
    "\n",
    "--> 안에 넣어줘도 안 된다고 나온다...\n",
    "\n",
    "\n",
    "`crawl_tweets(crawl_start, crawl_end)` 진행 시 오류\n",
    "\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-29-e4d276fc0ef7> in <module>()\n",
    "----> 1 tweet_results = crawl_tweets(crawl_start, crawl_end)\n",
    "\n",
    "TypeError: getJsonResponse() missing 2 required positional arguments: 'cookieJar' and 'proxy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @retry(total_try_cnt=3, sleep_in_sec=3, retryable_exceptions=(TimeoutError))\n",
    "# def my_method(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False):\n",
    "#     rand = random.randint(0, 9)\n",
    "#     logger.info(f\"rand={rand}\")\n",
    "\n",
    "#     if rand % 3 == 0:\n",
    "#         return True\n",
    "#     elif rand % 3 == 1:\n",
    "#         return False\n",
    "#     else:\n",
    "#         raise int(\"a\")\n",
    "\n",
    "# my_method(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retry(total_try_cnt=3, error_sleep=30, request_delay=2, retryable_exceptions=()):\n",
    "    \n",
    "#     def decorator(getJsonResponse):\n",
    "#         @functools.wraps(getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False))\n",
    "#         def getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False):\n",
    "#             \"\"\"\n",
    "#             Invoke an HTTP query to Twitter.\n",
    "#             Should not be used as an API function. A static method.\n",
    "#             \"\"\"\n",
    "            \n",
    "#             url = \"https://twitter.com/i/search/timeline?\"\n",
    "\n",
    "#             # URL\n",
    "\n",
    "#             if not tweetCriteria.topTweets:\n",
    "#                 url += \"f=tweets&\"\n",
    "\n",
    "#             url += (\"vertical=news&q=%s&src=typd&%s\"\n",
    "#                     \"&include_available_features=1&include_entities=1&max_position=%s\"\n",
    "#                     \"&reset_error_state=false\")\n",
    "\n",
    "#             urlGetData = ''\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'querySearch'):\n",
    "#                 urlGetData += tweetCriteria.querySearch\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'excludeWords'):\n",
    "#                 urlGetData += ' -'.join([''] + tweetCriteria.excludeWords)\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'username'):\n",
    "#                 if not hasattr(tweetCriteria.username, '__iter__'):\n",
    "#                     tweetCriteria.username = [tweetCriteria.username]\n",
    "\n",
    "#                 usernames_ = [u.lstrip('@') for u in tweetCriteria.username if u]\n",
    "#                 tweetCriteria.username = {u.lower() for u in usernames_ if u}\n",
    "\n",
    "#                 usernames = [' from:'+u for u in sorted(tweetCriteria.username)]\n",
    "#                 if usernames:\n",
    "#                     urlGetData += ' OR'.join(usernames)\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'within'):\n",
    "#                 if hasattr(tweetCriteria, 'near'):\n",
    "#                     urlGetData += ' near:\"%s\" within:%s' % (tweetCriteria.near, tweetCriteria.within)\n",
    "#                 elif hasattr(tweetCriteria, 'lat') and hasattr(tweetCriteria, 'lon'):\n",
    "#                     urlGetData += ' geocode:%f,%f,%s' % (tweetCriteria.lat, tweetCriteria.lon, tweetCriteria.within)\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'since'):\n",
    "#                 urlGetData += ' since:' + tweetCriteria.since\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'until'):\n",
    "#                 urlGetData += ' until:' + tweetCriteria.until\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'minReplies'):\n",
    "#                 urlGetData += ' min_replies:' + tweetCriteria.minReplies\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'minFaves'):\n",
    "#                 urlGetData += ' min_faves:' + tweetCriteria.minFaves\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'minRetweets'):\n",
    "#                 urlGetData += ' min_retweets:' + tweetCriteria.minRetweets\n",
    "\n",
    "#             if hasattr(tweetCriteria, 'lang'):\n",
    "#                 urlLang = 'l=' + tweetCriteria.lang + '&'\n",
    "#             else:\n",
    "#                 urlLang = ''\n",
    "            \n",
    "#             url = url % (urllib.parse.quote(urlGetData.strip()), urlLang, urllib.parse.quote(refreshCursor))\n",
    "#             useragent = useragent or TweetManager.user_agents[0]\n",
    "\n",
    "#             headers = [\n",
    "#                 ('Host', \"twitter.com\"),\n",
    "#                 ('User-Agent', useragent),\n",
    "#                 ('Accept', \"application/json, text/javascript, */*; q=0.01\"),\n",
    "#                 ('Accept-Language', \"en-US,en;q=0.5\"),\n",
    "#                 ('X-Requested-With', \"XMLHttpRequest\"),\n",
    "#                 ('Referer', url),\n",
    "#                 ('Connection', \"keep-alive\")\n",
    "#             ]\n",
    "\n",
    "#             if proxy:\n",
    "#                 opener = urllib.request.build_opener(urllib.request.ProxyHandler({'http': proxy, 'https': proxy}), urllib.request.HTTPCookieProcessor(cookieJar))\n",
    "#             else:\n",
    "#                 opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookieJar))\n",
    "#             opener.addheaders = headers\n",
    "\n",
    "#             if debug:\n",
    "#                 print(url)\n",
    "#                 # print('\\n'.join(h[0]+': '+h[1] for h in headers))\n",
    "\n",
    "            \n",
    "#             # HTTP Request 429 : 타임 슬립 줘보자\n",
    "#             time.sleep(request_delay)\n",
    "\n",
    "#             # JSON으로 정보 받아 오기\n",
    "\n",
    "#             for cnt in range(total_try_cnt):\n",
    "\n",
    "#                 logger.info(f\"{getJsonResponse.__name__}() : {cnt+1} / {total_try_cnt}\")\n",
    "                \n",
    "#                 try:\n",
    "#                     response = opener.open(url)\n",
    "#                     jsonResponse = response.read()\n",
    "#                     logger.info(f\"{getJsonResponse.__name__}() : {url}에서 데이터를 추출했습니다.\")\n",
    "\n",
    "#                 except retryable_exceptions as re:\n",
    "#                     print(f\"{re}: sleep {error_sleep}\")\n",
    "#                     time.sleep(error_sleep)                    \n",
    "#                     logger.info(f\"다시 시도: {getJsonResponse.__name__}()에서 {re}가 발생했습니다.\")\n",
    "                \n",
    "#                 try:\n",
    "#                     response = opener.open(url)\n",
    "#                     jsonResponse = response.read()\n",
    "                \n",
    "\n",
    "#                 # except TimeoutError as e:\n",
    "#                 #     print(\"Timeout error\")\n",
    "#                 #     print('sleep 30')\n",
    "#                 #     time.sleep(30)\n",
    "\n",
    "#                 #     # 이 부분 나중에 retry로 진행하기\n",
    "#                 #     try:\n",
    "#                 #         response = opener.open(url)\n",
    "#                 #         jsonResponse = response.read()\n",
    "#                 #     except TimeoutError as e:\n",
    "#                 #         print(\"Timeout Error again.\")\n",
    "#                 #         print(\"Pass Data\")\n",
    "#                 #         pass\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(\"An error occured during an HTTP request:\", str(e))\n",
    "#                     print(\"Try to open in browser: https://twitter.com/search?q=%s&src=typd\" % urllib.parse.quote(urlGetData))\n",
    "#                     logger.info(f\"{getJsonResponse.__name__}(): {e} 발생, url: {url}\")\n",
    "#                     # 이 부분 나중에 확인하기\n",
    "#                     print(\"sleep {error_sleep} and pass data\")\n",
    "#                     time.sleep(error_sleep)\n",
    "#                     pass\n",
    "#                     # sys.exit()                   \n",
    "                    \n",
    "#                 try:\n",
    "#                     s_json = jsonResponse.decode()\n",
    "#                 except:\n",
    "#                     logger.info(f\"{getJsonResponse.__name__}(): Invalid response from Twitter\")\n",
    "#                     print(\"Invalid response from Twitter\")\n",
    "#                     pass\n",
    "#                     # sys.exit()                    \n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         dataJson = json.loads(s_json)\n",
    "#                         # return dataJson\n",
    "#                     except:\n",
    "#                         logger.info(f\"{getJsonResponse.__name__}(): Json Parsing 에러, url: {url}\")\n",
    "#                         print(\"Error parsing JSON: %s\" % s_json)\n",
    "#                         pass\n",
    "#                         # sys.exit()\n",
    "                \n",
    "#                 if dataJson:\n",
    "#                     return dataJson\n",
    "\n",
    "#             logger.info(f\"{func.__name__}() : FAILED\")\n",
    "        \n",
    "#         return getJsonResponse\n",
    "#     return decorator\n",
    "\n",
    "# # @retry(total_try_cnt=3, )\n",
    "\n",
    "\n",
    "#                 # return dataJson\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @retry(total_try_cnt=3, error_sleep=20, request_delay=2, retryable_exceptions=(TimeoutError))\n",
    "# def crawl_tweets(start_date, end_date):    \n",
    "#     got.manager.TweetManager.getJsonResponse = getJsonResponse # (tweetCriteria, refreshCursor, cookieJar, proxy, useragent=None, debug=False) # 함수에 이 부분 넣어주고\n",
    "    \n",
    "#     print(\"========== 트윗 수집 시작: {0} ~ {1} ==========\".format(start_date, end_date))\n",
    "#     start_time = time.time()\n",
    "#     tweet_criteria = got.manager.TweetCriteria().setQuerySearch('Elon Musk')\\\n",
    "#                                                 .setSince(start_date)\\\n",
    "#                                                 .setUntil(end_date)\\\n",
    "#                                                 .setLang('en')\n",
    "#     tweets = got.manager.TweetManager.getTweets(tweet_criteria, debug=True)\n",
    "    \n",
    "#     elapsed_time = time.time()-start_time\n",
    "    \n",
    "#     print(\"수집 완료 : {}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n",
    "#     print(\"총 수집 트윗 개수 : {0}\".format(len(test_tweet)))\n",
    "    \n",
    "#     return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

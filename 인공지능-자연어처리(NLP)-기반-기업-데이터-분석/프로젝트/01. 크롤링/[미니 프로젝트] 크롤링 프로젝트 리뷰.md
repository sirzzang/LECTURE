# 크롤링 미니 프로젝트



## 1. 큰 그림



![crawl-big](images/crawl-big.png)



 우리가 만든 크롤링 코드들은 worker cluster 안에서 작동한다. 안에 함수를 전달한다. 여기서 함수를 실행한다. 자동으로 스케쥴링까지 되면, 함수들이 DB에서 데이터를 읽어서 action(크롤링을 하고 DB에 삽입한다 등)을 한다. 가능한 자원에 한계가 있기 때문에 클러스터로 구성한다. 이렇게 클러스터로 구성하기 위해 하둡, Celery 등을 사용해 분산처리한다. 사용할 수 있는 CPU 자원을 찾아서 함수를 실행시킨다. worker cluster 안에 데이터 모델링 등도 있다. 딥러닝은 하루 종일 할 때도 있고.

 주기적으로 작업을 시키고 싶다면, DB 클러스터 테이블에 schedule 테이블을 만든다. 스케쥴 단위로 체크하도록 한다. 그러면 worker 클러스터에서 읽고, 또 작업시키고 할 수 있다. 

 서비스에서 worker로 일을 시킬 때는 보통 자료구조로 `queue` 사용한다.







## 2. 코드 리뷰



### 2.1. 영화 댓글 크롤링

* 유튜브 스크롤 다운 : JavaScript 문법 사용.

  ```python
  try:
      while True:
          driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
  except:
      print("더보기 끝")
  ```

  - 자동으로 멈추는 건 아니고, 유저가 멈춰줘야 하는 구조.
  - 자동으로 멈추려면, 스크롤에서 **현재 포지션**이 어디인지 구한 후, 현재 스크롤 위치가 계속 같은 위치면(시간, 횟수 등) 멈춰주면 된다.

* 네이버 영화 유니코드 에러 : `\u1141` 등. 관련 stopword를 모아놓은 게 있을 것 같기도 한데, 강사님은 못 찾았다.

* 씨네 21에서 request GET 요청이 맞는데, 이 사이트에서처럼 POST 요청으로 만들어 놓는 경우도 있다. 전달해야 하는 폼 데이터 주의. `requests.post` 요청을 보내야 하고, 데이터도 보내야 한다.

* 다음 영화 : `dict.items()`에서 key와 value를 사용해서 데이터 저장.





### 2.2.  한미 영화 평점 비교

* 시각화 패키지로 Plotly 사용 : 커서에 따라 interaction이 되고, 예쁘다!

* 장르 dict에 3이 없다.

* selector : 검색하고 쓸 수 있는 정도면 충분하다. 경우의 수가 너무 많기 때문. selector로 선택하면 리스트로 오기 때문에, 이후 인덱싱이 필요하다.

  ```python
  try:
      genre_tags = movie_info_p_tags.select('span a[href*="genre="]')
      genre_tag_list = []
      for i in range(len(genre_tags)):
          genre_tag_elem = genre_tags[i].get_text()
          genre_tag_list.append(genre_tag_elem)
  except:
      except_list.append(movie_code)
  ```

* pickle 데이터 형식

  * 파이썬 객체도 결국 바이너리 데이터.
  * pickle은 파이썬의 리스트, 딕셔너리 등 다양한 변수나 함수를 그 자체로 바이너리 데이터로 인코딩한다.
  * pickle 데이터 저장하면 로드했을 때 함수, 변수 등이 그대로 불러와 진다.
  * 다만, 보안 상 문제가 있고 핸들링할 게 많다고 한다. 모델링할 때, 그 모델 자체를 저장할 때는 pickle 데이터를 많이 쓴다.  *~~(강사님은 별로 좋아하지는 않는다)~~*





### 2.3. 데일리 인포메이션

* Gmail 보내기 : `smtplb.SMTP()` ~ 작성(html form) ~ 발송.
  * SMTP 프로토콜 직접 구축할 수도 있으나, 비효율적.
  * 각각의 데이터를 추출해서 테이블에 넣는 과정에서 경우 분기가 많았다.
* Selenium 쓰면서 고정 요소가 있어서 클릭이 안 되는 문제가 있었던 걸로 안다. 했던 일 또 하고 또 하지 않기 위해서는 크롤링이 어디까지 됐는지 확인하는 게 좋다.





### 2.4. 맛집

* 네이버 맛집 크롤링
  * 네이버 지도에서 한 페이지에 있는 데이터 모두 가져오길 원했는데, 한 칸씩만 추출됐다. 그 이유를 아직 찾지는 못했으나, `headless` 옵션 주면 해결될 것 같기도 하다.
  * 현재 스크롤에서 4개밖에 보이지 않기 때문에, 다음 페이지로 이동해서 text를 찾자고 했다. 그러나 move하기 위해서도 스크롤을 하나씩 내린다. 너무 오래 걸린다. 아직 강사님도 이유를 잘 모르겠다.
* Selenium id로 찾았는데, 좋은 방법은 아니다. 의미가 없는 태그 id니까, 바뀔 수 있다. 이상한 값들이 들어가면, 그걸로 찾지 않는 것이 좋다. Angular JavaScript에서 임의로 만든 값일 가능성이 높다.
* request 보낼 때 POST 요청으로 보냈다.
* 지리 정보 가져올 때, JSON으로 요청하면 위도, 경도가 표시되는 경우도 있다. 위도, 경도가 생각보다 의미를 가지는 경우가 있어서, 같이 수집하면 좋다.
* 인스타그램 크롤링 어려운데, JSON으로도 가능하다. 까다로운 이유는 데이터에 특정한 hash값을 부여하고, 그것을 기반으로 다시 response를 주기 때문. 좋아요 한 것을 기반으로, 좋아요 누를 때마다 hash값이 달라진다. 선호하는 데이터(그림, 태그 등 어디에 반응하는지)를 찾기 때문에, hash값을 request줄 때 다음 요청 날릴 때 같이 날려주는 게 핵심.
* `implicitly wait(1000)` 시도했는데, 짧게 여러 번 주는 것을 추천. 찾으면 문제가 없는데, 못 찾으면 계속 기다리니까 효율적이지 않다.





### 2.5.  일론 머스크

* Google
  * 파라미터 쿼리 : `+` 연산자. 한 칸 띄우면 쿼리에 +가 연결된다. `""`(double quote)는 반드시 들어가야 한다는 쿼리 조건.
  * 구글이 그냥 하면 잘 안 가져오는 것처럼 보인다. 그러나 환경설정에서 데이터를 가져올 때 JavaScript를 끄면 된다.(debugger에서 Disable JavaScript 옵션 설정) 이렇게 해서 보낸다는 건, 동적으로 할 필요가 없다는 것. 
* TED
  * 의도적으로 가져가지 말라고 해서 힘들었던 부분이다.
  * Selenium의 한계일 수도 있다. 굉장히 많은 디테일을 설정해주어야 한다.
* Twitter : 발표 내용 약간 수정하면, Static Method가 아니더라도 함수 재정의는 가능하다.
* 네이버 기사 크롤링 : 페이지네이션에서 재귀 함수 사용한 부분.
* 유튜브 : API 쓴 부분과 쓰지 않은 부분. 구글 API와 똑같다. 역시 JavaScript 스크롤 다운 코드 있었다.





### 2.6. 채용 공고

* 인사이트 파라미터 분석 디테일 : cd, ty.
* html 구조 :  표 형식으로 가져올 수 있는 방법이 없나.
* 문자열 전처리 : 중간에 껴 있는 애들을 제거하기 위해서 `strip` 외에 `replace`도 진행.
*  자소설 닷컴
  * session을 통한 로그인 구현 : request 시 response가 생성되는데, 그 response를 대체로 쿠키 등에 저장한다. 로그인 시 session을 만들어서 요청을 보내고, 응답을 받는 순간 session을 유지시켜야 한다. 요청을 보낼 때마다 쿠키를 포함해서 날릴 수 있으므로 일관된 처리가 가능하다. 데이터가 오고 가는 데 있어서의 인증 모듈과 관련.
  * POST 요청 전송. 

* 카테고리 자체를 동적으로 컨트롤하기 위해 카테고리를 가져 온 부분이 좋다.
* style attribute 잘 활용하지는 않으나, 이 코드에서는 하나 밖에 없었던 것 같다.
* col span, row span 등 표를 깔끔하게 가져오는 방법을 검색하고, 코드를 차용한 부분이 좋았다.





---

# 느낀 점

* pseudo code 작성법, 함수 설명 작성법.
* DB에 넣는 방법 공부.
* 메일 보내는 방법.
* HTML 표 형식 예쁘게 가져오는 법.


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [복습]\n",
    "\n",
    "\n",
    "### 1. iframe\n",
    "\n",
    " iframe 태그로 구성되어 있는 html 페이지의 경우 request를 iframe의 소스 url로 보내야 한다.\n",
    " \n",
    " \n",
    "### 2. selenium\n",
    "\n",
    " 브라우저의 동작에 따라 element를 찾을 수도 있고, 못 찾을 수도 있다. element 선택은 xpath, class, id, css선택자 등으로 모두 가능하다. 단수 선택, 복수 선택 모두 가능하다.\n",
    " 드라이버가 올바른 데이터를 받아올 때까지 기다렸다가 페이지 소스를 받아와야 한다.\n",
    " \n",
    "---\n",
    " \n",
    "## [이전 시간 질문]\n",
    "\n",
    "1. 동적 handling : 과거의 댓글까지 모두 가져오려고 했는데, 닉네임마다 동적으로 정보가 변한다.\n",
    "> 동적으로 뜨는 댓글. F12 개발자도구 네트워크에서 더보기를 누를 때 어떻게 응답이 오는지 보면 된다. 응답으로 오는 메시지를 분석해서 핸들링한다. 즉, request를 똑같이 날려야 한다. 헤더 부분을 참조해서 request url 찾고, 각 부분에 맞춰서 넣어주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------- 0604 수업 ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인사이트\n",
    "\n",
    "- 파이널 프로젝트 진행하면서 그 사람이 썼던 댓글 필터링해야 하는지 아닌지에 대해 궁금증이 있었다. 오늘처럼 그 사람의 뉴스 히스토리를 모을 수 있다면 분석하는 데에 도움이 될 것이다.\n",
    "\n",
    "- 이전 파이널 프로젝트 때 댓글 크롤링할 때는 selenium 이용해서 더보기 버튼을 계속해서 클릭해 줬다. 그것보다 지금처럼 요청을 한 번에 보내고 json 데이터로 읽어와서 저장하는 게 더 빠를 것으로 보인다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제발...\n",
    "\n",
    "* `parse_qs`의 키, 값 쌍에서 값은 리스트다. 그대로 넣으면 안 된다. 인덱싱 통해 리스트 안의 문자열에 접근해야 한다!\n",
    "* request 보낼 때 안 되면 제일 먼저 url부터 확인합시다...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추후 고민\n",
    "- `sid` 파라미터\n",
    "- `userId` : user key값. --> 나중에 이거 바꾸면 그 사람의 히스토리 모두 다 가져올 수 있을 듯?\n",
    "- `page`, `pageSize` 활용하지 말고, 댓글 개수 읽어서 해당하는 개수만큼 json 데이터 가져오도록 조정하는 것은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic DOM 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링 목표\n",
    "1. 네이버 뉴스 리스트를 가져온다.\n",
    "2. 네이버 뉴스 리스트에 올라 있는 뉴스를 추출한다.\n",
    "3. 해당 네이버 뉴스의 댓글들을 추출한다.\n",
    "4. 댓글을 작성한 사용자에 기반해, 그 사용자가 작성한 댓글들을 모두 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링 개발 순서도\n",
    "\n",
    "1. URL 분석\n",
    "    - 1) XML / JSON / iframe 여부\n",
    "    - 2) 1)로 request 전송했을 때, 예상하던 response를 받을 수 있는지 여부.\n",
    "    - 3) 2)가 False일 경우, request 다시 확인.\n",
    "        - **`header`**와 **`params`**가 맞는지.\n",
    "        - 아니라면 다른 방법 모색 ex)Selenium.\n",
    "    \n",
    "    \n",
    "2. Parsing\n",
    "    - 1) 데이터 형태 : XML / JSON\n",
    "    - 2) 불순한 데이터가 존재하는지 여부 확인. 만약 존재한다면, 문자열 함수 등을 이용해 제거.\n",
    "    - 3) 각 데이터 형태에 맞는 방식으로 파싱.\n",
    "        - XML : `BeautifulSoup` 라이브러리 이용.\n",
    "        - JSON : `json.loads` 혹은 `resp.json()` 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import json\n",
    "from urllib.parse import parse_qs, urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 네이버 뉴스 URL을 분석한다.\n",
    "\n",
    "\n",
    "> 모든 페이지의 기사 목록을 가져 온다. 이미지까지 포함해서 가져 온다.\n",
    "\n",
    "\n",
    "### XML : BeautifulSoup 사용\n",
    "\n",
    "\n",
    "\n",
    "1. 가져와야 하는 정보 및 사이트\n",
    "    - 네이버 경제, 금융 뉴스\n",
    "    - 사이트 : https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259\n",
    "\n",
    "---\n",
    "\n",
    "2. URL 분석(url 파라미터)\n",
    "    - 카테고리 : `sid1`, `sid2`\n",
    "        - 경제(큰 카테고리) : `sid1`\n",
    "        - 하위 카테고리\n",
    "            - 금융 : https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259\n",
    "            - 증권 : https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=101&sid2=258\n",
    "    - 날짜 : date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&date=20200602\n",
      "Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "# url 분해\n",
    "base_url = \"https://news.naver.com/main/list.nhn\" # 뒷부분 : ?mode=LS2D&mid=shm&sid1=101&sid2=259\n",
    "params = {\n",
    "    'mode' : 'LS2D',\n",
    "    'mid' : 'shm',\n",
    "    'sid1' : 101, # category1 : 경제\n",
    "    'sid2' : 259, # category2 : 금융\n",
    "    'date' : '20200602' # date\n",
    "}\n",
    "\n",
    "# 요청 보내고 제대로 오는지 체크\n",
    "req = requests.get(base_url, params=params)\n",
    "print(f\"URL: {req.url}\")\n",
    "print(f\"Status Code: {req.status_code}\")\n",
    "\n",
    "# 텍스트 데이터 잘 수신했는지 확인\n",
    "# print(req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 네이버 뉴스 내용을 가져 온다.\n",
    "\n",
    "\n",
    "### XML : BeautifulSoup 사용\n",
    "\n",
    "\n",
    "\n",
    "**구조 확인**\n",
    "    \n",
    "![news-cat](./images/web_21.png)\n",
    "\n",
    "    - 태그 구조 확인 : `ul` > `li`\n",
    "    - 작업 개략 : 반복문 돌려서 li 태그만 다 찾아온다.\n",
    "    \n",
    "    \n",
    "    \n",
    "**내용 추출 : 헤드라인 + 상세 내용**\n",
    "    \n",
    "![news](./images/web_22.png)\n",
    "    \n",
    "    \n",
    "    * 이미지 있는 경우\n",
    "        - 첫 번째 `dt` : 이미지\n",
    "        - 두 번째 `dt` : 헤드라인\n",
    "    * 이미지 없는 경우 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Headline List : 20\n"
     ]
    }
   ],
   "source": [
    "# soup객체 만들기\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "# 반복 통해 뉴스 헤드라인 추출\n",
    "news_headline_wrap_uls = soup.find('ul', class_='type06_headline')\n",
    "news_wrap_uls = soup.find('ul', class_='type06')\n",
    "news_headline_list = news_headline_wrap_uls.find_all('li', recursive=False) + news_wrap_uls.find_all('li', recursive=False) # li를 하나씩만 가져오면 되므로, recursive 옵션 False.\n",
    "print(f\"Length of Headline List : {len(news_headline_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진이 있는 경우와 없는 경우 분리\n",
    "news_results = []\n",
    "\n",
    "for news_headline in news_headline_list:    \n",
    "    \n",
    "    # dt 태그 \n",
    "    dt_tags = news_headline.find_all('dt')    \n",
    "    if len(dt_tags) > 1: # 이미지 있음.\n",
    "        img_src = dt_tags[0].find('img')['src'] # 이미지 url\n",
    "        headline = dt_tags[1].find('a').get_text(strip=True)\n",
    "        news_url = dt_tags[1].find('a')['href']        \n",
    "    elif len(dt_tags) == 1: # 이미지 없음.\n",
    "        img_src = None \n",
    "        headline = dt_tags[0].find('a').get_text(strip=True)\n",
    "        news_url = dt_tags[0].find('a')['href']        \n",
    "    else: # dt가 없는 경우 : 모르겠음.\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # dd 태그 : description\n",
    "    dd_tags = news_headline.find('dd')    \n",
    "    if dd_tags: # dd 태그 있음.\n",
    "        desc = dd_tags.find('span', class_='lede').get_text(strip=True)\n",
    "        writing = dd_tags.find('span', class_='writing').get_text(strip=True)        \n",
    "\n",
    "    else:\n",
    "        desc = None\n",
    "        writing = None\n",
    "        \n",
    "    # 정보를 모아서 news_dict 생성  \n",
    "    news_dict = {\n",
    "        'image' : img_src,\n",
    "        'headline' : headline,\n",
    "        'url' : news_url,\n",
    "        'desc' : desc,\n",
    "        'press' : writing        \n",
    "    }\n",
    "    \n",
    "    # 결과 리스트에 저장\n",
    "    news_results.append(news_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 네이버 뉴스의 댓글을 가져 온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순서도\n",
    "\n",
    "* 문서 구조 파악.\n",
    "* request 찾기.\n",
    "* url 분석.\n",
    "* parameter 변환.\n",
    "* response 분석.\n",
    "* response parsing\n",
    "* 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 순서 : 요청하기 -> 분석하기\n",
    "\n",
    "\n",
    "> 뉴스 상세 페이지에 들어가서 댓글을 가져온다.\n",
    "\n",
    "- 댓글 더보기 탭을 찾아야 한다.\n",
    "- 댓글이 많으면 댓글 더보기 페이지에서도, 더 보기 버튼을 계속 눌러야 한다.\n",
    "- 이 요청을 개발자도구 네트워크 탭을 통해 확인하면 다음과 같다.\n",
    "    \n",
    "![comments](./images/web_23.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**맨 아래 셀에서 진행한 연습을 바탕으로 함수 만들어 받아온다.**\n",
    "\n",
    "* `request_comment_list`\n",
    "    - 한 뉴스 기사에 대한 모든 댓글의 json 데이터를 text 형태로 받아 온다.\n",
    "    - 이 함수에서는 일단 요청만 보낸다.\n",
    "    - 따라서 json 댓글 데이터가 문자열로 되어 있는 html 페이지가 반환될 것이다.\n",
    "    \n",
    "    \n",
    "* `request_user_comment_list`\n",
    "    - 해당 유저의 댓글 히스토리. \n",
    "    - comment number만 파라미터로 추가된다.\n",
    "    \n",
    "    \n",
    "* `comment_resp_to_json` \n",
    "    - 댓글들의 리스트에 요청을 보내 받아 온 결과 html을 text로 반환한다.\n",
    "    - json으로 바꾼다.\n",
    "    - 파이썬의 딕셔너리 형태로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_comment_list(oid, aid):\n",
    "    \n",
    "    \"\"\"\n",
    "    뉴스 url을 기반으로 해당 뉴스 댓글 데이터 페이지에 request를 보내는 함수.\n",
    "    \n",
    "    * parameter\n",
    "        - oid: 본문 url의 oid 쿼리.\n",
    "        - aid: 본문 url의 aid 쿼리.\n",
    "    \n",
    "    * return\n",
    "        - 요청을 보낸 후 파싱한 html.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 댓글 api url\n",
    "    comment_base_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json\"\n",
    "    \n",
    "    # 댓글 페이지 comment parameter\n",
    "    params = {\n",
    "        'ticket' : 'news',\n",
    "        'pool' : 'cbox5',\n",
    "        'lang' : 'ko',\n",
    "        'country': 'KR',       \n",
    "        \n",
    "        'objectId' : f'news{oid},{aid}', # 각각의 뉴스 url --> 바꿔야할 값.\n",
    "        'pageSize' : 1000, # --> 그 이상이면 바꿔서 요청 한 번 더 보내야 함.\n",
    "        'indexSize': 10,\n",
    "        'page': 1, # --> 페이지\n",
    "        'includeAllStatus': 'true',\n",
    "        'cleanbotGrade':2\n",
    "    }\n",
    "    \n",
    "    # 댓글 페이지 요청 headers\n",
    "    headers = {\n",
    "        'referer': f\"https://news.naver.com/main/read.nhn?m_view=1&includeAllCount=true&mode=LS2D&mid=shm&sid1=101&sid2=259&oid={oid}&aid={aid}\"\n",
    "    }\n",
    "    \n",
    "    # URL 요청 보내기\n",
    "    req = requests.get(comment_base_url, params=params, headers=headers)\n",
    "    # print(f\"해당 뉴스에서의 댓글 URL: {req.url}  / status: {req.status_code}\")\n",
    "    \n",
    "    html = req.text\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_user_comment_list(oid, aid, comment_no):\n",
    "    \n",
    "    \"\"\"\n",
    "    뉴스 url에서 접속한 해당 뉴스 댓글 데이터 페이지를 이용해,\n",
    "    각 사용자가 작성한 댓글 데이터 페이지에 request를 보내는 함수.\n",
    "    \n",
    "    * parameter\n",
    "        - oid: 뉴스 본문 url의 oid 쿼리.\n",
    "        - aid: 뉴스 본문 url의 aid 쿼리.\n",
    "        - comment_no: 해당 사용자를 식별하는 commentNo 쿼리.\n",
    "    \n",
    "    * return\n",
    "        - 요청을 보낸 후 파싱한 html.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 댓글 api url\n",
    "    user_comment_base_url = \"https://apis.naver.com/commentBox/cbox/web_neo_user_info_jsonp.json\"\n",
    "    \n",
    "    # 댓글 페이지 comment parameter\n",
    "    params = {\n",
    "        'ticket' : 'news',\n",
    "        'pool' : 'cbox5',\n",
    "        'lang' : 'ko',\n",
    "        'country': 'KR',     \n",
    "        'objectId' : f'news{oid},{aid}', # 각각의 뉴스 url --> 바꿔야할 값.\n",
    "        'pageSize' : 1000, # --> 그 이상이면 바꿔서 요청 한 번 더 보내야 함.\n",
    "        'indexSize': 10,\n",
    "        'page': 1, # --> 페이지\n",
    "        'includeAllStatus': 'true',\n",
    "        'cleanbotGrade':2,\n",
    "        'commentNo' : comment_no\n",
    "    }\n",
    "    \n",
    "    # 댓글 페이지 요청 headers\n",
    "    headers = {\n",
    "        'referer': f\"https://news.naver.com/main/read.nhn?m_view=1&includeAllCount=true&mode=LS2D&mid=shm&sid1=101&sid2=259&oid={oid}&aid={aid}\"\n",
    "    }\n",
    "    \n",
    "    # URL 확인\n",
    "    req = requests.get(user_comment_base_url, params=params, headers=headers)\n",
    "    # print(f\"해당 유저가 작성한 댓글의 URL: {req.url}  / status: {req.status_code}\")\n",
    "    \n",
    "    html = req.text\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_resp_to_json(html):\n",
    "    \n",
    "    \"\"\"\n",
    "    응답으로 온 html 텍스트를 분석하여 파이썬의 객체로 만드는 함수.\n",
    "    \n",
    "    * parameter\n",
    "        - html : <Response.text>\n",
    "    \n",
    "    * return\n",
    "        - 응답 데이터가 저장되어 있는 파이썬 dict.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    comment_text = html[10:-2] # comment_text : 문자열.\n",
    "    comment_resp_dict = json.loads(comment_text) # json 데이터를 파이썬의 dictionary 형태로 바꿔 준다.\n",
    "    \n",
    "    # 댓글 몇 개 있는지 체크\n",
    "    comment_list = comment_resp_dict['result']['commentList']\n",
    "    print(f\"Total: {len(comment_list)}\")\n",
    "\n",
    "    return comment_resp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 댓글 저장\n",
    "\n",
    " 댓글 json api를 저장한다. 나중에 필요한 부분만 따다 쓰면 됨.\n",
    " \n",
    "### 해당 유저의 댓글 히스토리 저장\n",
    "\n",
    "> 해당 유저가 작성한 댓글의 히스토리에 접근하는 방법을 아직 강사님은 발견하지 못하셨다고 합니다! 일단 어떤 뉴스 들어가서 그 사람의 id를 통해 접근해서 히스토리를 모으는 방법을 사용한다.\n",
    "\n",
    "* 위에서 저장한 댓글을 더 보기하면, commentNo가 뜬다.\n",
    "* commentNo로 url 바꿔주면 그 사람의 댓글 히스토리를 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=022&aid=0003471097\n",
      "Total: 2\n",
      "Total: 80\n",
      "Total: 58\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=028&aid=0002499591\n",
      "Total: 5\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=421&aid=0004673081\n",
      "Total: 1\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=421&aid=0004673055\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=005&aid=0001327728\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=016&aid=0001681395\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=018&aid=0004655069\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=029&aid=0002601944\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=011&aid=0003747679\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=018&aid=0004655052\n",
      "Total: 1\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=008&aid=0004418824\n",
      "Total: 1\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=001&aid=0011650984\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=421&aid=0004672993\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=016&aid=0001681385\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=014&aid=0004436037\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=030&aid=0002885918\n",
      "Total: 4\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 22\n",
      "Total: 48\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=009&aid=0004587427\n",
      "Total: 65\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 47\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 1\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 66\n",
      "Total: 25\n",
      "Total: 11\n",
      "Total: 49\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 82\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 76\n",
      "Total: 100\n",
      "Total: 42\n",
      "Total: 2\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 87\n",
      "Total: 100\n",
      "Total: 9\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 100\n",
      "Total: 21\n",
      "Total: 100\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=009&aid=0004587426\n",
      "Total: 1\n",
      "Total: 100\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=009&aid=0004587425\n",
      "Total: 0\n",
      "뉴스 페이지 주소: https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=101&sid2=259&oid=009&aid=0004587424\n",
      "Total: 0\n"
     ]
    }
   ],
   "source": [
    "user_comment_history = {}\n",
    "\n",
    "for result in news_results:\n",
    "    \n",
    "    url = result['url'] # 해당 뉴스 주소\n",
    "    parsed_url = urlparse(url) # 쿼리셋\n",
    "    queries = parse_qs(parsed_url.query)\n",
    "    oid, aid = queries['oid'][0], queries['aid'][0] # oid, aid 바뀐다!\n",
    "    print(f\"뉴스 페이지 주소: {url}\")\n",
    "    \n",
    "    # 댓글 페이지에 요청 보내기\n",
    "    comment_html = request_comment_list(oid, aid)\n",
    "    \n",
    "    # html -> json -> dict\n",
    "    comment_dict = comment_resp_to_json(comment_html)\n",
    "    comment = comment_dict.get('result').get('commentList')\n",
    "    \n",
    "    result['comment'] = comment\n",
    "    \n",
    "    # 각 댓글의 작성자에게 요청 보내기\n",
    "    if comment is None:\n",
    "        continue\n",
    "    \n",
    "    for c in comment:\n",
    "        commentNo = c.get('commentNo')\n",
    "        user_comment_html = request_user_comment_list(oid, aid, commentNo)\n",
    "        \n",
    "        # html -> json -> dict\n",
    "        user_comment_dict = comment_resp_to_json(user_comment_html)\n",
    "        user_comment = user_comment_dict.get('result').get('commentList')\n",
    "        # pprint(user_comment)\n",
    "        \n",
    "        user_id = user_comment[0].get('userIdNo') # 어차피 안에 있는 댓글들의 작성자는 다 똑같다.\n",
    "        user_name = user_comment[0].get('userName')\n",
    "        \n",
    "        # 키 설정\n",
    "        user_key = f\"{user_id} / {user_name}\"\n",
    "        \n",
    "        user_comment_history.setdefault(user_key, [])\n",
    "        user_comment_history[user_key].append(user_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 댓글 json으로 받아오기 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요청 보내주기\n",
    "\n",
    "1. parameter 살펴보기\n",
    "\n",
    "    - parameter가 많다.\n",
    "    - parameter 주석처리해보면서 하나씩 바꿔 보고, 제대로 받아오는지 확인한다.\n",
    "    - 나중에 필요할 수 있지만 지금 당장 필요한 것은 아닐 수 있다.\n",
    "    - 공백으로 되어 있는 건 일단 주석처리해도 된다.\n",
    "\n",
    "\n",
    "---\n",
    "### 데이터 받아 오기\n",
    "\n",
    "2. 댓글 json 데이터로 받아 온다.\n",
    "    - javascript 코드 문자열 바꿀 수 있다.\n",
    "    - `json.load` 진행해야 함.\n",
    "    - 문자열 슬라이싱 통해 잘라줌.\n",
    "        ```\n",
    "        '_callback({\"success\":true,\"code\":\"1000\",\"message\":\"요청을 성공적으로 처리하였습니다.\",\"lang\":\"ko\",\"country\":\"KR\",\"result\":{\"commentList\":[{\"ticket\":\"news\"\n",
    "        \n",
    "        (중략...)\n",
    "        \n",
    "        \"sort\":\"FAVORITE\",\"bestList\":[]},\"date\":\"2020-06-04T01:34:00+0000\"});'\n",
    "        ```\n",
    "---\n",
    "### 한 번에 진행\n",
    "3. 변수 조정을 통해 한 번에 받아올 수 있지 않을까? + 파라미터 정리하자.\n",
    "    - pageSize\n",
    "    - page\n",
    "    - objectId\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_resp = requests.get(comment_base_url, params=params, headers=headers)\n",
    "print(comment_resp.url)\n",
    "\n",
    "# 확인\n",
    "comment_text = comment_resp.text\n",
    "comment_text = comment_text[10:-2] # comment_text : 문자열.\n",
    "comment_resp_dict = json.loads(comment_text) # json 데이터를 파이썬의 dictionary 형태로 바꿔 준다.\n",
    "comment_list = comment_resp_dict['result']['commentList']\n",
    "print(f\"Total Comments: {len(comment_list)}\")\n",
    "print(comment_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 댓글 더 보기 창에 들어가기 위해 어떤 요청을 보내야 하는가?\n",
    "\n",
    "> 요청을 보낼 때 네트워크에서 웹이 어떻게 동작하는지 찾는다. request와 response의 내용을 분석한 후, 바뀌는 파라미터만 찾아서 요청을 다르게 보내주면 된다.\n",
    "\n",
    "![header](./images/web_24.png)\n",
    "\n",
    "![url](./images/web_25.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- requests 보낼 때 바뀌는 url 분석.\n",
    "- 파라미터 일일이 분석 후, 동적으로 컨트롤해야 할 요소 필터링하기 : `pageSize`, `page`, `objectId`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 댓글 요청 url 분석\n",
    "\n",
    "comment_base_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json\"\n",
    "\n",
    "# ?ticket=news&templateId=default_economy&pool=cbox5&_callback=jQuery1124021036404387583252_1591233733835\n",
    "# &lang=ko&country=KR&objectId=news015%2C0004352610&categoryId=&pageSize=20\n",
    "# &indexSize=10&groupId=&listType=OBJECT\n",
    "# &pageType=more&page=3&refresh=false&sort=FAVORITE&current=2142689022\n",
    "# &prev=2142644342&includeAllStatus=true&cleanbotGrade=2&_=1591233330121\n",
    "\n",
    "params = {\n",
    "    'ticket': 'news',\n",
    "    'templateId': 'default_economy',\n",
    "    'pool':'cbox5',\n",
    "    # '_callback': '',\n",
    "    'lang':'ko',\n",
    "    'country': 'KR',\n",
    "    'objectId':'news015,0004352610',\n",
    "    # 'categoryId': '',\n",
    "    'pageSize': 20,\n",
    "    'indexSize': 10,\n",
    "    # 'groupId':'',\n",
    "    'listType':'OBJECT',\n",
    "    'pageType': 'more',\n",
    "    'page': 2,\n",
    "    'refresh': 'false',\n",
    "    'sort': 'FAVORITE',    \n",
    "    # 'current': 2142689022,\n",
    "    # 'prev': 2142644342,\n",
    "    'includeAllStatus': 'true',\n",
    "    'cleanbotGrade':2,\n",
    "    # '_': 1591233330121\n",
    "}\n",
    "\n",
    "# 헤더 맞춰주기 :referer\n",
    "headers= {\n",
    "    'referer': 'https://news.naver.com/main/read.nhn?m_view=1&includeAllCount=true&mode=LS2D&mid=shm&sid1=101&sid2=259&oid=015&aid=0004352610'}\n",
    "comment_resp = requests.get(comment_base_url, params=params, headers=headers)\n",
    "# comment_resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "\n",
      "Total Comments: 20\n"
     ]
    }
   ],
   "source": [
    "# 2. json 데이터 분석\n",
    "\n",
    "comment_text = comment_resp.text\n",
    "comment_text = comment_text[10:-2] # comment_text : 문자열.\n",
    "comment_resp_dict = json.loads(comment_text) # json 데이터를 파이썬의 dictionary 형태로 바꿔 준다.\n",
    "print(type(comment_resp_dict))\n",
    "print('')\n",
    "# pprint(comment_resp_dict) # 파이썬의 json 객체가 된다.\n",
    "\n",
    "# 댓글 확인\n",
    "comment_list = comment_resp_dict['result']['commentList']\n",
    "print(f\"Total Comments: {len(comment_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&pool=cbox5&lang=ko&country=KR&objectId=news015%2C0004352610&pageSize=100&indexSize=10&page=1&includeAllStatus=true&cleanbotGrade=2\n",
      "Total Comments: 56\n"
     ]
    }
   ],
   "source": [
    "# 3. url 찾기 연습 : pageSize, page 조정을 통해 한 번에 가져오자. + 파라미터 정리.\n",
    "comment_base_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json\"\n",
    "\n",
    "params = {\n",
    "    'ticket': 'news',\n",
    "    # 'templateId': 'default_economy',\n",
    "    'pool':'cbox5',\n",
    "    # '_callback': '',\n",
    "    'lang':'ko',\n",
    "    'country': 'KR',\n",
    "    'objectId':'news015,0004352610', # --> 이 부분 oid, aid로 조정하면 된다.\n",
    "    # 'categoryId': '',\n",
    "    'pageSize': 100, # -> 이 부분 조정.\n",
    "    'indexSize': 10,\n",
    "    # 'groupId':'',\n",
    "    #'listType':'OBJECT',\n",
    "    #'pageType': 'more',\n",
    "    'page': 1, # -> 이 부분 조정.\n",
    "    #'refresh': 'false',\n",
    "    #'sort': 'FAVORITE',    \n",
    "    # 'current': 2142689022,\n",
    "    # 'prev': 2142644342,\n",
    "    'includeAllStatus': 'true',\n",
    "    'cleanbotGrade':2,\n",
    "    # '_': 1591233330121\n",
    "}\n",
    "\n",
    "# 헤더 맞춰주기 :referer\n",
    "headers= {\n",
    "    'referer': 'https://news.naver.com/main/read.nhn?m_view=1&includeAllCount=true&mode=LS2D&mid=shm&sid1=101&sid2=259&oid=015&aid=0004352610'}\n",
    "comment_resp = requests.get(comment_base_url, params=params, headers=headers)\n",
    "print(comment_resp.url)\n",
    "\n",
    "# 확인\n",
    "comment_text = comment_resp.text\n",
    "comment_text = comment_text[10:-2] # comment_text : 문자열.\n",
    "comment_resp_dict = json.loads(comment_text) # json 데이터를 파이썬의 dictionary 형태로 바꿔 준다.\n",
    "comment_list = comment_resp_dict['result']['commentList']\n",
    "print(f\"Total Comments: {len(comment_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 정리 : 뉴스 url 바꿔 가면서 댓글 json 가져오기\n",
    "\n",
    "* 축약해야 할 파라미터를 찾는다.\n",
    "* 각각의 뉴스 url에서의 `oid`와 `aid` 부분이 json 데이터에서 `ObjectID`를 이룬다.\n",
    "\n",
    "```\n",
    "comment_base_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json\"\n",
    "\n",
    "params = {\n",
    "    'ticket' : 'news',\n",
    "    'pool' : 'cbox5',\n",
    "    'lang' : 'ko',\n",
    "    'country': 'KR',\n",
    "    'objectId' : 'news015,0004352610', # --> 바꿔야할 값.\n",
    "    'pageSize' : 1000, # 그 이상이면 바꿔서 요청 한 번 더 보내야 함.\n",
    "    'page': 1, # 페이지\n",
    "    'includeAllStatus': 'true',\n",
    "    'cleanbotGrade':2\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'referer': 'https://news.naver.com/main/read.nhn?m_view=1&includeAllCount=true&mode=LS2D&mid=shm&sid1=101&sid2=259&oid=015&aid=0004352610'\n",
    "}\n",
    "\n",
    "comment_resp = requests.get(comment_base_url, params=params, headers=headers)\n",
    "\n",
    "# 확인\n",
    "comment_text = comment_resp.text\n",
    "comment_text = comment_text[10:-2] # comment_text : 문자열.\n",
    "comment_resp_dict = json.loads(comment_text) # json 데이터를 파이썬의 dictionary 형태로 바꿔 준다.\n",
    "comment_list = comment_resp_dict['result']['commentList']\n",
    "print(f\"Total Comments: {len(comment_list)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 사람의 댓글 히스토리를 받아오기 위해서는 다음과 같이 네트워크를 분석한다.\n",
    "\n",
    "![comcom](./images/web_26.png)\n",
    "![history](./images/web_27.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

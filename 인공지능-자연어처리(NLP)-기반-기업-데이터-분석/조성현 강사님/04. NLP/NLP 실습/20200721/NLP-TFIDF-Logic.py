# -*- coding: utf-8 -*-
"""NLP-TFIDF-logic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OIoj6ofGowSi3Y0QCEdSknmfZYhJ2b0X
"""

import numpy as np

# vocabulary 생성
def build_dictionary(corpus):
    vocab_dict = {}
    for c in corpus:
        vocabs = c.strip().split() # 각 문장 내 unique 어휘 찾기
        for vocab in vocabs:
            vocab_key = vocab.lower() # 소문자 변환
            if vocab_key not in vocab_dict: # dictonary 내 색인 생성
                vocab_dict[vocab_key] = 0
    
    return sorted(vocab_dict)

# TF 계산
def calc_TF(corpus, vocab_dict):
    flag = len(vocab_dict)
    TF_matrix = [[v, 0]  for _ in range(len(corpus)) for v in vocab_dict]
    for i in range(len(corpus)):
        sent = corpus[i].strip().lower().split()
        vocab_cnt = 0
        for s in sent:
            for vocab in TF_matrix[i*flag:(i+1)*flag]:
                if s == vocab[0]:
                    vocab[1] += 1 # 빈도 추가
                    vocab_cnt += 1 # 총 등장 빈도 수
        # print(f"{sent}에서 총 등장한 어휘 빈도 수 : {vocab_cnt}")
        for j in range(flag):
            TF_matrix[i*flag:(i+1)*flag][j][1] /= vocab_cnt

    return TF_matrix

# IDF 계산
def calc_IDF(corpus, vocab_dict):
    # IDF 행렬 초기화
    IDF_matrix = [[vocab, 0] for vocab in vocab_dict]

    # IDF 계산
    for j in range(len(IDF_matrix)):
        for i in range(1, len(corpus)):
            sent = corpus[i].strip().lower().split()
            if IDF_matrix[j][0] in sent:
                IDF_matrix[j][0]
                IDF_matrix[j][1] += 1
    
    for i in range(len(IDF_matrix)):
        IDF_matrix[i][1] = np.log((len(corpus)-1)/IDF_matrix[i][1])

    return IDF_matrix * len(corpus)

# TF-IDF 계산
def calc_TFIDF(TF, IDF, corpus, vocab_dict):
    flag = len(vocab_dict)
    TFIDF_matrix = []

    TFIDF_matrix = []
    for i in range(len(corpus)):
        tf = np.array([tf[1] for tf in TF[i*flag:(i+1)*flag]], dtype=np.float32)
        idf = np.array([idf[1] for idf in IDF[i*flag:(i+1)*flag]], dtype=np.float32)
        TFIDF_matrix.append(tf*idf)
    return np.array(TFIDF_matrix).T

# 코사인 유사도 계산
def calc_cos_sim(A, B):
    # 분자
    bunja = A * B

    # 분모
    norm_A, norm_B = 0, 0
    for a in A:
        norm_A += a**2
    for b in B:
        norm_B += b**2
    bunmo = np.sqrt(norm_A) * np.sqrt(norm_B)

    return (bunja / bunmo).T.sum()

# 테스트
sentences = [
             'gold silver truck',
             'Shipment of gold damaged in a fire',
             'Delivery of silver arrived in a silver truck',
             'Shipment of gold arrived in a truck'
             ]

dictionary = build_dictionary(sentences)
print(f"vocabulary 사전: \n{dictionary}")
print("")

tf_matrix = calc_TF(sentences, dictionary)
print(f"Term Frequency: \n{tf_matrix}")
print("")

idf_matrix = calc_IDF(sentences, dictionary)
print(f"Inverse Document Frequency: \n{idf_matrix}")
print("")

tfidf_matrix = calc_TFIDF(tf_matrix, idf_matrix, sentences, dictionary)
print(f"TF-IDF: \n{tfidf_matrix}")
print("")

cos_sim_docs = {}
for i in range(1, len(sentences)):
    cos_sim_docs[sentences[i]] = calc_cos_sim(tfidf_matrix.T[0], tfidf_matrix.T[i])
print(f"문서 간 코사인유사도: \n{cos_sim_docs}")


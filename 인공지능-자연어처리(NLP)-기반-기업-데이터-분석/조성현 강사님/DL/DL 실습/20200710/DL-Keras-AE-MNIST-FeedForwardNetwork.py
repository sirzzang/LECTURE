# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10sZnYbQiVnAWW-Vs1SCuyYtqsIYvlDox
"""

# module import
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
import pickle
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import numpy as np

# 경로 설정
root_path = "/content/drive/My Drive/멀티캠퍼스/[혁신성장] 인공지능 자연어처리 기반/[강의]/조성현 강사님"
data_path = f"{root_path}/dataset"

# 데이터 로드
with open(f"{data_path}/mnist.pickle", 'rb') as f:
    mnist = pickle.load(f)

# 데이터 확인
dir(mnist)

# input data: 3000개만 사용
X_data = mnist.data[:3000]
X_image = X_input.copy() # 그림 그려 보는 용도
X_target = mnist.target[:3000] # 확인용

# 데이터 픽셀 표준화
scaler = StandardScaler()
X_data = scaler.fit_transform(X_data.T).T # 표준화 방향 주의

# 노드 설정
X_input.shape # 784 차원 벡터 3000개(이미지 개수)
n_input = X_input.shape[1]
n_feature = int(input('축소할 차원 수 설정: ')) # 784 feature를 이만큼으로 줄인다.
n_output = n_input # 입력과 출력 같음

# 그래프 모델 생성
x_Input = Input(batch_shape=(None, n_input))
x_Encoder = Dense(256, activation='sigmoid')(x_Input) # 인코더 1층
x_Encoder = Dense(n_feature, activation='sigmoid')(x_Encoder) # 인코더 2층
y_Decoder = Dense(256, activation='sigmoid')(x_Encoder) # 디코더 1층
y_Decoder = Dense(n_output, activation='linear')(y_Decoder) # 디코더 2층

model = Model(x_Input, y_Decoder)
model.compile(loss='mse', optimizer=Adam(lr=0.01))
print("====== AutoEncoder 모델: 전체 구조 ======")
print(model.summary())

# autoencoder 학습
EPOCHS = int(input('학습 횟수 설정: '))
BATCH = int(input('배치 사이즈 설정: '))
ae_hist = model.fit(X_data, X_data, epochs=EPOCHS, batch_size=BATCH)

# latent feature
encoder = Model(x_Input, x_Encoder)
print("====== AutoEncoder 모델: 인코더 부분 ======")
print(encoder.summary())

# 군집화
# Kmeans++ 알고리즘
km = KMeans(n_clusters=10, init='k-means++', n_init=3, max_iter=300, tol=1e-04, random_state=42, verbose=1)
km.fit(mnist_latent)
clust = km.predict(mnist_latent)

# 클러스터별 이미지 확인
for k in np.unique(clust):
    # 클러스터가 k인 이미지 10개를 찾는다.
    idx = np.where(clust == k)[0][:10]

    f1 = plt.figure(figsize=(8, 2)) # 원래 이미지
    f2 = plt.figure(figsize=(8, 2)) # latent vector
    for i in range(10):
        image = X_image[idx[i]].reshape(28, 28)        
        ax1 = f1.add_subplot(1, 10, i+1)
        ax1.imshow(image, cmap=plt.cm.bone)
        ax1.grid(False)
        ax1.set_title(f"{k}-original")
        ax1.xaxis.set_ticks([])
        ax1.yaxis.set_ticks([])

        image_latent = mnist_latent[idx[i]].reshape(10, 10)
        ax2 = f2.add_subplot(1, 10, i+1)        
        ax2.imshow(image_latent, cmap='Greys')        
        ax2.grid(False)
        ax2.set_title(f"{k}-latent")
        ax2.xaxis.set_ticks([])
        ax2.yaxis.set_ticks([])

        plt.tight_layout()
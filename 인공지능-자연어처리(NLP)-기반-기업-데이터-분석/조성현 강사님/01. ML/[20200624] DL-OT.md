

<sup>출처가 명시되지 않은 모든 자료(이미지 등)는 조성현 강사님 블로그 및 강의 자료 기반.</sup>

<< 딥러닝 >>



# [Tensorflow]



## 1. 역사



* 2011 Google Brain 팀에서 시작. 당시 1세대 시스템, 이름은 DistBelief.

* 2015 2세대 머신러닝 시스템 Tensorflow 오픈소스 공개.

  > Facebook: PyTorch

  

* 2019년 9월 Tensorflow 2.0.



## 2. 설치

* 일단은 CPU 2.1.0 버전으로 설치.
* GPU 활용하려면 Colab 사용.



### 2.1. GPU

 Tensorflow, Keras 모두 GPU 있으면 GPU에서 동작. 내부적으로 코드 짜지 않아도 알아서 GPU에서 동작하도록 해 놨다.



* GPU 역사



![image-20200624163955927](lecture-markdown/images/image-20200624163955927.png)



> GTX, RTX 등 붙은 게 게임용. Tesla V100의 경우 연산용. ~~*이거 코랩에서 쓰는 GPU인 것 같은데?*~~



 행렬 연산의 경우, 병렬 처리가 좋다. 구글에서는 텐서(스칼라, 벡터, 행렬 모두 다 지칭하는 데이터 타입)들의 곱셈을 전문으로 하는 칩을 만들어 내기도 했다. 이건 `TPU`라고 부른다. 

 NVIDIA도 가만히 있을 수가 없다! 이전의 CUDA 코어에 더해 Tensor 전용 코어를 만들고, 작은 행렬을 컴퓨터 쿨럭 한 사이클 내에 곱할 수 있도록 한다. 이 때부터 가격이 뛴다. 연산 전용 GPU의 경우 1500만 원 정도... 





* CPU와의 차이



![image-20200624164339238](lecture-markdown/images/image-20200624164339238.png)



 GPU에는 비디오 메모리라는 global memory가 있다. 메인 메모리와 GPU는 고속의 주변 장치. 컴퓨터 마더 보드에 Northbridge로 연결되어 있다. 저속의 주변 장치(키보드, 마우스, 하드디스크 등)는 저속 Southbridge로 연결되어 있다. 

 일반적으로 코드 짜면 메인 메모리에 저장된다. 이걸 불러 와서 실행하면 CPU에 있는 레지스터로 옮겨 가서 실행한다. 이게 GPU에서 돌아가게 하려면, 코드들이 들어갈 때 메인 메모리에 있는 데이터들을 읽어 가서 처리할 때, GPU의 비디오 메모리로 옮긴 다음에 써야 한다. `cudaMemcpy` 등. 메인 메모리와 GPU의 비디오 메모리 간 전송이 일어난다.



> `torch.device()`, `torch.to('cpu') `그런 과정인가?



 GPU는 행렬 곱셈이 왜 빠를까? GPU에서는 코어를 1메가 개 할당한다. 모든 코어가 원소를 하나씩(독립적으로) 계산한다. CPU(`a.k.a 페라리`)는 속도가 중요하고, GPU(`a.k.a 버스`)는 단위 시간 당 얼마나 많은 일을 하는지를 보고 따진다. CPU는 칩의 질로 승부하지만, GPU는 양으로, 코어를 많이 가진 것으로 승부한다.



 GPU는 특히 Single Instruction Multiple Data에 유리하다. 단일 명령어로 여러 개 데이터를 처리하는 방식에 해당한다. 곱하고 더하고 하는 연산을 모든 행렬의 원소마다 똑같이 쓴다. 그럴 때 유리하다. C라는 행렬에서 이 원소는 곱하기, 더하기를 해야 하고, 저 원소는 나누기 곱하기를 해야 한다고 달라지면 GPU가 못 한다. 원소들이 모두 **똑같은** 일을 하는 애들이기 때문에 GPU가 유리하고, 그런 방식을 SIMD 방식이라고 한다. 



 CPU는 Single Instruction Single Data로 처리하는 데에 유리하다. 물론 CPU도 코어 할당해서 가능한데 딥러닝은 전부 행렬 곱셈이다. 그래서 GPU로 처리하는 게 유리하다!



# [행렬 곱셈]



 행렬 곱셈이 얼마나 연산이 많이 필요한 일인지 보자.

 4x4 행렬 manually 행렬 곱셈을 해보자.

```python
# 4x4 matrix
a = np.array([[1,2,3,4],\
              [4,5,6,7],\
              [1,2,3,4],\
              [4,5,6,7]])

# 손으로 짜보기 1 : 좀 꼼수 느낌...
answer1 = np.zeros(16).reshape(4, 4)
for row in range(a.shape[0]):
    for col in range(a.shape[1]):
        print(f"{row}행 * {col}열")
        print(f"{a[row, :]} x {a[:, col]}")
        answer1[row, col] = np.dot(a[row, :], a[:, col].T)
print(answer1)

print('')

# 손으로 짜보기 2
answer2 = np.zeros(16).reshape(4, 4)
for row in range(a.shape[0]):
    for col in range(a.shape[1]):
        print(f"{row}행 * {col}열")
        for i in range(4):
            answer2[row][col] += (a[row][i] * a[i][col])
        print(f"계산 결과: {answer2[row][col]}")
print(answer2)

# 강사님 정답
c = np.zeros(a.shape) # 한 번에 이렇게 하면 된다.
for i in range(a.shape[0]):
    for j in range(a.shape[1]):
        for k in range(a.shape[0]):
            c[i, j] += (a[i, k] * a[k, j])
print(c)
```



`for문`이 3번 들어가니까, 시간복잡도가 `O(n^3)`이다. 연산량이 굉장히 많다.
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "base_dir = \"C:/python_CPUENV/PJ/Multicampus/Crawl\"\n",
    "tweet_saved_folder = f\"{base_dir}/tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이상 데이터 확인\n",
    "\n",
    " 일단 text가 없는 게 있나 확인하고, text 없는 것만 바꿔주기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-01-01_2015-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-02-01_2015-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-03-01_2015-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-04-01_2015-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-05-01_2015-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-06-01_2015-06-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-07-01_2015-07-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-08-01_2015-08-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-09-01_2015-09-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-10-01_2015-10-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-11-01_2015-11-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-12-01_2015-12-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-01-01_2016-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-02-01_2016-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-03-01_2016-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-04-01_2016-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-05-01_2016-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-06-01_2016-06-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-07-01_2016-07-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-08-01_2016-08-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-09-01_2016-09-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-10-01_2016-10-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-11-01_2016-11-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-12-01_2016-12-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-01-01_2017-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-02-01_2017-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-03-01_2017-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-04-01_2017-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-05-01_2017-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-06-01_2017-06-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-07-01_2017-07-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-08-01_2017-08-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-09-01_2017-09-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-10-01_2017-10-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-11-01_2017-11-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-12-01_2017-12-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-01-01_2018-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-02-01_2018-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-03-01_2018-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-04-01_2018-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-05-01_2018-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-06-01_2018-06-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-07-01_2018-07-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-08-01_2018-08-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-09-01_2018-09-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-10-01_2018-10-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-11-01_2018-11-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-12-01_2018-12-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-01-01_2019-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-02-01_2019-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-03-01_2019-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-04-01_2019-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-05-01_2019-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-06-01_2019-06-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-07-01_2019-07-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-08-01_2019-08-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-09-01_2019-09-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-10-01_2019-10-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-11-01_2019-11-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-11-11_2019-11-12.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-12-01_2019-12-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-01-01_2020-01-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-02-01_2020-02-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-03-01_2020-03-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-04-01_2020-04-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-05-01_2020-05-02.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-05-02_2020-05-03.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-05-03_2020-05-04.csv',\n",
       " 'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-06-01_2020-06-02.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all saved tweet files\n",
    "tweet_files = []\n",
    "\n",
    "for root_dir, sub_dir, files in os.walk(tweet_saved_folder):\n",
    "    for fname in files:\n",
    "        fname_ext = os.path.splitext(fname)[-1].lower()\n",
    "        if fname_ext == \".csv\":\n",
    "            tweet_files.append(os.path.join(root_dir, fname))\n",
    "\n",
    "tweet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-01-01_2015-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-02-01_2015-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-03-01_2015-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-04-01_2015-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-05-01_2015-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-06-01_2015-06-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-07-01_2015-07-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-08-01_2015-08-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-09-01_2015-09-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-10-01_2015-10-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-11-01_2015-11-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2015-12-01_2015-12-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-01-01_2016-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-02-01_2016-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-03-01_2016-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-04-01_2016-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-05-01_2016-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-06-01_2016-06-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-07-01_2016-07-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-08-01_2016-08-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-09-01_2016-09-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-10-01_2016-10-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-11-01_2016-11-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2016-12-01_2016-12-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-01-01_2017-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-02-01_2017-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-03-01_2017-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-04-01_2017-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-05-01_2017-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-06-01_2017-06-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-07-01_2017-07-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-08-01_2017-08-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-09-01_2017-09-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-10-01_2017-10-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-11-01_2017-11-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2017-12-01_2017-12-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-01-01_2018-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-02-01_2018-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-03-01_2018-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-04-01_2018-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-05-01_2018-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-06-01_2018-06-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-07-01_2018-07-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-08-01_2018-08-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-09-01_2018-09-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-10-01_2018-10-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-11-01_2018-11-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2018-12-01_2018-12-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-01-01_2019-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-02-01_2019-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-03-01_2019-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-04-01_2019-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-05-01_2019-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-06-01_2019-06-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-07-01_2019-07-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-08-01_2019-08-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-09-01_2019-09-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-10-01_2019-10-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-11-01_2019-11-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-11-11_2019-11-12.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2019-12-01_2019-12-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-01-01_2020-01-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-02-01_2020-02-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-03-01_2020-03-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-04-01_2020-04-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-05-01_2020-05-02.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-05-02_2020-05-03.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sir95\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-05-03_2020-05-04.csv\n",
      "File Path : C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\tweets_2020-06-01_2020-06-02.csv\n"
     ]
    }
   ],
   "source": [
    "# 트위터 내용에 결측값 있으면 결측값 제거 후 다시 저장\n",
    "for tweet_file in tweet_files:    \n",
    "    print(f\"File Path : {tweet_file}\")\n",
    "    \n",
    "    tweet_df = pd.read_csv(tweet_file)\n",
    "    if tweet_df.text.isnull().sum(): # 결측값 있으면\n",
    "        print(\"Drop NA Text Column\")\n",
    "        tweet_df.dropna(subset=['text'], inplace=True)    \n",
    "        tweet_df.to_csv(tweet_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 스키마 및 형식 맞추기\n",
    "\n",
    "* 조에서 정한 형식 : url_origin, name, date, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2015': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-01-01_2015-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-02-01_2015-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-03-01_2015-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-04-01_2015-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-05-01_2015-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-06-01_2015-06-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-07-01_2015-07-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-08-01_2015-08-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-09-01_2015-09-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-10-01_2015-10-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-11-01_2015-11-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2015-12-01_2015-12-02.csv'],\n",
      " '2016': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-01-01_2016-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-02-01_2016-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-03-01_2016-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-04-01_2016-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-05-01_2016-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-06-01_2016-06-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-07-01_2016-07-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-08-01_2016-08-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-09-01_2016-09-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-10-01_2016-10-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-11-01_2016-11-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2016-12-01_2016-12-02.csv'],\n",
      " '2017': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-01-01_2017-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-02-01_2017-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-03-01_2017-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-04-01_2017-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-05-01_2017-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-06-01_2017-06-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-07-01_2017-07-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-08-01_2017-08-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-09-01_2017-09-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-10-01_2017-10-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-11-01_2017-11-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2017-12-01_2017-12-02.csv'],\n",
      " '2018': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-01-01_2018-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-02-01_2018-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-03-01_2018-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-04-01_2018-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-05-01_2018-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-06-01_2018-06-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-07-01_2018-07-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-08-01_2018-08-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-09-01_2018-09-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-10-01_2018-10-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-11-01_2018-11-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2018-12-01_2018-12-02.csv'],\n",
      " '2019': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-01-01_2019-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-02-01_2019-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-03-01_2019-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-04-01_2019-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-05-01_2019-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-06-01_2019-06-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-07-01_2019-07-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-08-01_2019-08-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-09-01_2019-09-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-10-01_2019-10-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-11-01_2019-11-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2019-12-01_2019-12-02.csv'],\n",
      " '2020': ['C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-01-01_2020-01-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-02-01_2020-02-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-03-01_2020-03-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-04-01_2020-04-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-05-01_2020-05-02.csv',\n",
      "          'C:/python_CPUENV/PJ/Multicampus/Crawl/tweets\\\\tweets_2020-06-01_2020-06-02.csv']}\n"
     ]
    }
   ],
   "source": [
    "# get all saved tweet files\n",
    "tweet_files = {}\n",
    "\n",
    "for root_dir, sub_dir, files in os.walk(tweet_saved_folder):\n",
    "    for fname in files:\n",
    "        fname_ext = os.path.splitext(fname)[-1].lower()\n",
    "        fname_year, fname_day = fname[7:11], fname[15:17]\n",
    "        \n",
    "        # set default value\n",
    "        tweet_files.setdefault(fname_year, [])\n",
    "        \n",
    "        if fname_ext == \".csv\" and fname_day == '01':\n",
    "            tweet_files[fname_year].append(os.path.join(root_dir, fname))\n",
    "\n",
    "pprint(tweet_files) # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate file paths\n",
    "def to_output(files, year_key):\n",
    "    yield from files[year_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change schema and export \n",
    "def csv_out(df, df_name, output_path=\"output\"):\n",
    "    print(\" \")\n",
    "    print(f\"     Export Start : {df_name}\")\n",
    "    \n",
    "    # change dtime format\n",
    "    df.date = df.date.str.replace('-', '.')\n",
    "    df[['date', 'time']] = df.date.str.split(n=2, expand=True).rename({0: 'date', 1: 'time'}, axis=1)\n",
    "\n",
    "    # change column name and orders\n",
    "    df.rename(columns = {'url': 'url_origin', \n",
    "                         'user': 'name',\n",
    "                         'text': 'content'}, inplace=True)\n",
    "    df_to_output = df[['url_origin', 'name', 'date', 'content']]\n",
    "    \n",
    "    # export csv file\n",
    "    export_path = f\"{output_path}/{df_name}\"\n",
    "    df_to_output.to_csv(export_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    #check    \n",
    "    display(df_to_output.head())\n",
    "    \n",
    "    print(f\"     Export Done. : Check {export_path}\")\n",
    "    print(\" \")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : 1634\n",
      "Data : 523\n",
      "Data : 531\n",
      "Data : 1663\n",
      "Data : 17994\n",
      "Data : 2059\n",
      "Data : 1093\n",
      "Data : 1180\n",
      "Data : 1149\n",
      "Data : 1795\n",
      "Data : 479\n",
      "Data : 1146\n",
      "======================== △ Done : 2015 △ ========================\n",
      "\n",
      "Data : 2932\n",
      "Data : 1702\n",
      "Data : 1124\n",
      "Data : 14493\n",
      "Data : 1977\n",
      "Data : 2962\n",
      "Data : 1630\n",
      "Data : 4568\n",
      "Data : 5856\n",
      "Data : 3455\n",
      "Data : 3577\n",
      "Data : 2233\n",
      "======================== △ Done : 2016 △ ========================\n",
      "\n",
      "Data : 847\n",
      "Data : 3216\n",
      "Data : 2480\n",
      "Data : 5457\n",
      "Data : 10280\n",
      " \n",
      "     Export Start : tweets_2017-06-01_2017-06-02.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_origin</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/JZukawski/status/870429749...</td>\n",
       "      <td>JZukawski</td>\n",
       "      <td>2017.06.01</td>\n",
       "      <td>You're right I dont... But for hardened suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/ThePerezHilton/status/8704...</td>\n",
       "      <td>ThePerezHilton</td>\n",
       "      <td>2017.06.01</td>\n",
       "      <td>Hopefully others follow @elonmusk's lead!! htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/LuisACCruz1/status/8704297...</td>\n",
       "      <td>LuisACCruz1</td>\n",
       "      <td>2017.06.01</td>\n",
       "      <td>@AOL Elon Musk bails on Trump's advisory counc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/HockingHick/status/8704297...</td>\n",
       "      <td>HockingHick</td>\n",
       "      <td>2017.06.01</td>\n",
       "      <td>Newsflash. America not great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/faranj/status/870429735872...</td>\n",
       "      <td>faranj</td>\n",
       "      <td>2017.06.01</td>\n",
       "      <td>Elon Musk to Trump: You quit Paris, so I quit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          url_origin            name  \\\n",
       "0  https://twitter.com/JZukawski/status/870429749...       JZukawski   \n",
       "1  https://twitter.com/ThePerezHilton/status/8704...  ThePerezHilton   \n",
       "2  https://twitter.com/LuisACCruz1/status/8704297...     LuisACCruz1   \n",
       "3  https://twitter.com/HockingHick/status/8704297...     HockingHick   \n",
       "4  https://twitter.com/faranj/status/870429735872...          faranj   \n",
       "\n",
       "         date                                            content  \n",
       "0  2017.06.01  You're right I dont... But for hardened suppor...  \n",
       "1  2017.06.01  Hopefully others follow @elonmusk's lead!! htt...  \n",
       "2  2017.06.01  @AOL Elon Musk bails on Trump's advisory counc...  \n",
       "3  2017.06.01                      Newsflash. America not great.  \n",
       "4  2017.06.01  Elon Musk to Trump: You quit Paris, so I quit ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Export Done. : Check output/tweets_2017-06-01_2017-06-02.csv\n",
      " \n",
      "Data : 4329\n",
      "Data : 2058\n",
      "Data : 5456\n",
      "Data : 3068\n",
      "Data : 4205\n",
      "Data : 2982\n",
      "Data : 5749\n",
      "======================== △ Done : 2017 △ ========================\n",
      "\n",
      "Data : 2610\n",
      "Data : 13246\n",
      "Data : 3441\n",
      "Data : 8217\n",
      "Data : 2917\n",
      "Data : 7339\n",
      "Data : 4991\n",
      "Data : 10509\n",
      "Data : 3198\n",
      "Data : 10559\n",
      "Data : 8847\n",
      "Data : 7013\n",
      "======================== △ Done : 2018 △ ========================\n",
      "\n",
      "Data : 9978\n",
      "Data : 10167\n",
      "Data : 17547\n",
      "Data : 11200\n",
      "Data : 9158\n",
      "Data : 9829\n",
      "Data : 6811\n",
      "Data : 6708\n",
      "Data : 4149\n",
      "Data : 9645\n",
      "Data : 11676\n",
      "Data : 18216\n",
      "======================== △ Done : 2019 △ ========================\n",
      "\n",
      "Data : 10300\n",
      "Data : 22469\n",
      "Data : 4728\n",
      "Data : 12963\n",
      "Data : 136798\n",
      "Data : 22646\n",
      "======================== △ Done : 2020 △ ========================\n",
      "\n",
      "Total 545757 Tweets.\n"
     ]
    }
   ],
   "source": [
    "# change schema and count total data\n",
    "\n",
    "data_cnt = 0\n",
    "\n",
    "for year in tweet_files.keys():\n",
    "    gen = to_output(tweet_files, year)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            fname = next(gen)\n",
    "            df = pd.read_csv(fname)\n",
    "            \n",
    "            df_name = fname.split('\\\\')[-1]\n",
    "            \n",
    "            # 중복 파일 작업 방지\n",
    "            try:\n",
    "                if df_name not in os.listdir(\"output\"): \n",
    "                    csv_out(df, df_name)\n",
    "            except:\n",
    "                os.makedirs(\"output\")\n",
    "                csv_out(df, df_name)\n",
    "            else:\n",
    "                # count data\n",
    "                print(f\"Data : {df.shape[0]}\")\n",
    "                data_cnt += df.shape[0]\n",
    "                \n",
    "    except StopIteration:\n",
    "        print(f\"======================== △ Done : {year} △ ========================\")\n",
    "        print(\"\")\n",
    "        pass\n",
    "\n",
    "print(f\"Total {data_cnt} Tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

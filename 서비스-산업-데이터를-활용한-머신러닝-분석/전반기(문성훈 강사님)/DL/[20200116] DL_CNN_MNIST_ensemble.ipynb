{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[20200116] tensorflow_CNN_ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNioPR4DhgAA8khnLkm+Fiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirzzang/TIL_multicampus_lecturefile/blob/master/machine%20learning%20%EA%B0%95%EC%9D%98%ED%8C%8C%EC%9D%BC/%5B20200116%5D%20tensorflow_CNN_MNIST_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUCsu3g6SUv1",
        "colab_type": "text"
      },
      "source": [
        "### **궁금했던 내용**\n",
        "\n",
        "\n",
        "1. 모델 만드는 node는 `loop`안에 돌리지 말고, tensor로 설정해 둔다.\n",
        "    ```python\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
        "    Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
        "    drop_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "    x_img = tf.reshape(X, [-1,28,28,1])\n",
        "\n",
        "    L1 = tf.layers.conv2d(inputs=x_img, filters=32, kernel_size=[3,3], padding=\"SAME\", strides=1, activation=tf.nn.relu)\n",
        "    L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding=\"SAME\", strides=2)\n",
        "    L1 = tf.layers.dropout(inputs=L1, rate=drop_rate)\n",
        "\n",
        "    L2 = tf.layers.conv2d(inputs=L1, filters=64, kernel_size=[3,3], padding=\"SAME\", strides=1, activation=tf.nn.relu)\n",
        "    L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding=\"SAME\", strides=2)\n",
        "    L2 = tf.layers.dropout(inputs=L2, rate=drop_rate)\n",
        "\n",
        "    L2 = tf.reshape(L2, [-1, 7*7*64])\n",
        "\n",
        "    dense1 = tf.layers.dense(inputs=L2, units=256, activation=tf.nn.relu)\n",
        "    dense1 = tf.layers.dropout(inputs=dense1, rate=drop_rate)\n",
        "\n",
        "    dense2 = tf.layers.dense(inputs=dense1, units=128, activation=tf.nn.relu)\n",
        "    dense2 = tf.layers.dropout(inputs=dense2, rate=drop_rate)\n",
        "\n",
        "    dense3 = tf.layers.dense(inputs=dense2, units=512, activation=tf.nn.relu)\n",
        "    dense3 = tf.layers.dropout(inputs=dense3, rate=drop_rate)\n",
        "\n",
        "    H = tf.layers.dense(inputs=dense3, units=10)\n",
        "\n",
        "    cost = tf.losses.softmax_cross_entropy(Y, H)\n",
        "\n",
        "    train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    ```\n",
        "2. 학습을 for loop 안에 넣어서 돌린다.\n",
        "* np.zeros() : 인자로 차원, shape만 주면 된다. reshape 사용해서 어렵게 할 필요 없다.\n",
        "\n",
        "    ```python\n",
        "    # 학습\n",
        "\n",
        "    initial_predict = np.zeros([mnist.test.num_examples,10])  \n",
        "        # 차원만 주면 된다 안에! \n",
        "\n",
        "    for i in range(num_of_models):\n",
        "\n",
        "        print((i+1),\"번째 가설\")  \n",
        "\n",
        "        print(\"시간이 오래 걸립니다. 마음의 준비를 하세요.\")\n",
        "        num_of_epoch = 30\n",
        "        batch_size = 100\n",
        "\n",
        "        for step in range(num_of_epoch):\n",
        "            num_of_iter = int(mnist.train.num_examples / batch_size)\n",
        "            cost_val = 0\n",
        "            for j in range(num_of_iter):\n",
        "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "                _, cost_val = sess.run([train, cost], feed_dict = { X : batch_x,\n",
        "                                                                    Y : batch_y,\n",
        "                                                                    drop_rate : 0.3})        \n",
        "\n",
        "        print((i+1),\"번째 가설 학습이 완료되었습니다.\")    \n",
        "\n",
        "        result = np.array(sess.run(H, feed_dict = { X : mnist.test.images }))     \n",
        "        \n",
        "        initial_predict += result\n",
        "\n",
        "    print(initial_predict)\n",
        "    \n",
        "    ```\n",
        "\n",
        "3. `enumerate` 사용하려면, class, OOP 사용해야 한다.\n",
        "    * 어제 안 됐던 부분 : tensor로서 가설 사용하려면 그래프 초기화하면 안 된다.\n",
        "\n",
        "4. `tf.layers.dense` 함수에서는 softmax 사용하지 않았기 때문에 예측값이 0과 1 사이의 수로 도출되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7yxxJ1AeSNG",
        "colab_type": "code",
        "outputId": "cf8e1f4a-a7a7-412b-8a35-fce78a6f3aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfMMsOKha-Br",
        "colab_type": "code",
        "outputId": "a384e4a2-6189-4211-928c-7be51291f0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 몇 명에게 가설을 물어볼 거니?\n",
        "num_of_models = int(input())\n",
        "\n",
        "# 가설을 여러 개 만드는 연습을 해보자.\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
        "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
        "drop_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "x_img = tf.reshape(X, [-1,28,28,1])\n",
        "\n",
        "L1 = tf.layers.conv2d(inputs=x_img, filters=32, kernel_size=[3,3], padding=\"SAME\", strides=1, activation=tf.nn.relu)\n",
        "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding=\"SAME\", strides=2)\n",
        "L1 = tf.layers.dropout(inputs=L1, rate=drop_rate)\n",
        "\n",
        "L2 = tf.layers.conv2d(inputs=L1, filters=64, kernel_size=[3,3], padding=\"SAME\", strides=1, activation=tf.nn.relu)\n",
        "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding=\"SAME\", strides=2)\n",
        "L2 = tf.layers.dropout(inputs=L2, rate=drop_rate)\n",
        "\n",
        "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
        "\n",
        "dense1 = tf.layers.dense(inputs=L2, units=256, activation=tf.nn.relu)\n",
        "dense1 = tf.layers.dropout(inputs=dense1, rate=drop_rate)\n",
        "\n",
        "dense2 = tf.layers.dense(inputs=dense1, units=128, activation=tf.nn.relu)\n",
        "dense2 = tf.layers.dropout(inputs=dense2, rate=drop_rate)\n",
        "\n",
        "dense3 = tf.layers.dense(inputs=dense2, units=512, activation=tf.nn.relu)\n",
        "dense3 = tf.layers.dropout(inputs=dense3, rate=drop_rate)\n",
        "\n",
        "H = tf.layers.dense(inputs=dense3, units=10)\n",
        "\n",
        "cost = tf.losses.softmax_cross_entropy(Y, H)\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# 학습\n",
        "\n",
        "initial_predict = np.zeros([mnist.test.num_examples,10])  # 차원만 주면 된다 안에! \n",
        "\n",
        "for i in range(num_of_models):\n",
        "\n",
        "    print((i+1),\"번째 가설\")  \n",
        "\n",
        "    print(\"시간이 오래 걸립니다. 마음의 준비를 하세요.\")\n",
        "    num_of_epoch = 30\n",
        "    batch_size = 100\n",
        "\n",
        "    for step in range(num_of_epoch):\n",
        "        num_of_iter = int(mnist.train.num_examples / batch_size)\n",
        "        cost_val = 0\n",
        "        for j in range(num_of_iter):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            _, cost_val = sess.run([train, cost], feed_dict = { X : batch_x,\n",
        "                                                                Y : batch_y,\n",
        "                                                                drop_rate : 0.3})        \n",
        "\n",
        "    print((i+1),\"번째 가설 학습이 완료되었습니다.\")    \n",
        "\n",
        "    result = np.array(sess.run(H, feed_dict = { X : mnist.test.images }))     \n",
        "    \n",
        "    initial_predict += result\n",
        "\n",
        "print(initial_predict)\n",
        "\n",
        "# 정확도 측정\n",
        "\n",
        "prediction = tf.argmax(initial_predict, 1)\n",
        "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, dtype = tf.float32))\n",
        "accuracy_rate = sess.run(accuracy, feed_dict = { X : mnist.test.images,\n",
        "                                                Y : mnist.test.labels,\n",
        "                                                drop_rate : 0})\n",
        "print(f\"정확도는 {accuracy_rate * 100}% 입니다.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "1 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "1 번째 가설 학습이 완료되었습니다.\n",
            "2 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "2 번째 가설 학습이 완료되었습니다.\n",
            "3 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "3 번째 가설 학습이 완료되었습니다.\n",
            "4 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "4 번째 가설 학습이 완료되었습니다.\n",
            "5 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "5 번째 가설 학습이 완료되었습니다.\n",
            "6 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "6 번째 가설 학습이 완료되었습니다.\n",
            "7 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "7 번째 가설 학습이 완료되었습니다.\n",
            "8 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "8 번째 가설 학습이 완료되었습니다.\n",
            "9 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "9 번째 가설 학습이 완료되었습니다.\n",
            "10 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "10 번째 가설 학습이 완료되었습니다.\n",
            "11 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "11 번째 가설 학습이 완료되었습니다.\n",
            "12 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "12 번째 가설 학습이 완료되었습니다.\n",
            "13 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "13 번째 가설 학습이 완료되었습니다.\n",
            "14 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "14 번째 가설 학습이 완료되었습니다.\n",
            "15 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "15 번째 가설 학습이 완료되었습니다.\n",
            "16 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "16 번째 가설 학습이 완료되었습니다.\n",
            "17 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "17 번째 가설 학습이 완료되었습니다.\n",
            "18 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "18 번째 가설 학습이 완료되었습니다.\n",
            "19 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "19 번째 가설 학습이 완료되었습니다.\n",
            "20 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "20 번째 가설 학습이 완료되었습니다.\n",
            "21 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "21 번째 가설 학습이 완료되었습니다.\n",
            "22 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "22 번째 가설 학습이 완료되었습니다.\n",
            "23 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "23 번째 가설 학습이 완료되었습니다.\n",
            "24 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "24 번째 가설 학습이 완료되었습니다.\n",
            "25 번째 가설\n",
            "시간이 오래 걸립니다. 마음의 준비를 하세요.\n",
            "25 번째 가설 학습이 완료되었습니다.\n",
            "[[-4687.28277206 -2773.54403019 -3135.08037806 ...   461.82504082\n",
            "  -3635.76250458 -2876.44646454]\n",
            " [-3064.4747963  -3136.57480812   559.18213081 ... -2139.38010025\n",
            "  -2939.58929825 -3291.35899353]\n",
            " [-1837.63289261   535.95387268 -1271.67940331 ... -1310.62822533\n",
            "  -1471.20205402 -1515.37879562]\n",
            " ...\n",
            " [-3922.72684097 -4249.00827026 -3603.19491386 ... -3351.75465584\n",
            "  -2846.63739395 -2211.07951546]\n",
            " [-2044.20656776 -1989.31406784 -2715.41027069 ... -1875.8542366\n",
            "  -1437.93685722 -1262.5892849 ]\n",
            " [-1926.148633   -2506.64439869 -2218.1466732  ... -3583.95843124\n",
            "  -1665.76169205 -2345.74920845]]\n",
            "정확도는 99.36000108718872% 입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ8REUJmSddJ",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------\n",
        "*밑에는 짜면서 연습했던 내용*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ6yt1k4h7pE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-Uds37LTaa",
        "colab_type": "code",
        "outputId": "345af3b8-d502-4ba2-c755-f0c8882d0877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "prediction = sess.run(tf.argmax(initial_predict, 1))\n",
        "print(prediction)\n",
        "print(len(prediction))\n",
        "\n",
        "actual = sess.run(tf.argmax(Y, 1), feed_dict = { Y : mnist.test.labels})\n",
        "print(actual)\n",
        "print(len(actual))\n",
        "\n",
        "is_correct = sess.run(tf.equal(prediction, actual))\n",
        "print(is_correct)\n",
        "\n",
        "accuracy = sess.run(tf.reduce_mean(tf.cast(is_correct, dtype = tf.float32)))\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 ... 4 5 6]\n",
            "10000\n",
            "[7 2 1 ... 4 5 6]\n",
            "10000\n",
            "[ True  True  True ...  True  True  True]\n",
            "0.9926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itglen95KCHi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-n7_kaEc4ET",
        "colab_type": "code",
        "outputId": "e8f0ccde-4d08-4c66-819d-68814f71f5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "# 일단 저 위에가 i번째 가설이 맞다고 본다면\n",
        "# 예측값 뽑아내는 연습을 일단 해보자.\n",
        "# 이 셀에서 하는 건 각 가설에 대한 예측값은 아닐 것이다.\n",
        "# 위에서 두 번 돌렸으니까 두 번째 가설에 대한 예측값일 것.\n",
        "# 그럼에도 불구하고, 일단 예측값을 nd.array로 받아서 원소끼리 받는 연습을 해보기 위해서 뽑아지나 보는 것.\n",
        "\n",
        "# Q) 왜 -261, -195 이렇게 나올까..? 더해서 1인 확률이 나와야 하는 게 아닌가..?\n",
        "\n",
        "# print(mnist.test.images[0]) # scale되어 있음.\n",
        "\n",
        "tmp_result = sess.run(H, feed_dict = { X : mnist.test.images})\n",
        "print(tmp_result)\n",
        "\n",
        "plt.imshow(mnist.test.images[0].reshape(28, 28), cmap = \"gray\")\n",
        "\n",
        "# 7번째가 가장 크긴 한데, 뭘 잘못 생각하고 있는 것인가!\n",
        "# learning_rate, epoch 달랐다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-532.18677    -93.39636   -104.97832   ...    2.1812797 -246.65646\n",
            "   -64.695366 ]\n",
            " [-193.36827    -89.21035     18.05369   ... -203.33128   -228.38773\n",
            "  -403.02585  ]\n",
            " [-121.61318    269.28503    -69.79396   ... -175.05673   -139.18822\n",
            "  -273.3978   ]\n",
            " ...\n",
            " [-324.24985    -95.750305  -127.89657   ...  -80.402565   -81.77541\n",
            "   -58.5296   ]\n",
            " [-163.28249    -39.68734   -179.16678   ... -105.0597      -1.3729067\n",
            "   -23.47257  ]\n",
            " [-207.51788   -229.77101   -309.5963    ... -546.51355   -130.74165\n",
            "  -404.08075  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcaf44202e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAM3ElEQVR4nO3dXahc9bnH8d/vpCmI6UXiS9ik0bTB\nC8tBEo1BSCxbQktOvIjFIM1FyYHi7kWUFkuo2It4WaQv1JvALkrTkmMJpGoQscmJxVDU4o5Es2NI\njCGaxLxYIjQRJMY+vdjLso0za8ZZa2ZN8nw/sJmZ9cya9bDMz7VmvczfESEAV77/aroBAINB2IEk\nCDuQBGEHkiDsQBJfGeTCbHPoH+iziHCr6ZW27LZX2j5o+7Dth6t8FoD+cq/n2W3PkHRI0nckHZf0\nmqS1EfFWyTxs2YE+68eWfamkwxFxJCIuSPqTpNUVPg9AH1UJ+zxJx6a9Pl5M+xzbY7YnbE9UWBaA\nivp+gC4ixiWNS+zGA02qsmU/IWn+tNdfL6YBGEJVwv6apJtsf8P2VyV9X9L2etoCULeed+Mj4qLt\nByT9RdIMSU9GxP7aOgNQq55PvfW0ML6zA33Xl4tqAFw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIO\nJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnC\nDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9Dw+uyTZPirpnKRPJV2MiCV1NAWgfpXCXrgrIv5Rw+cA\n6CN244EkqoY9JO2wvcf2WKs32B6zPWF7ouKyAFTgiOh9ZnteRJywfb2knZIejIjdJe/vfWEAuhIR\nbjW90pY9Ik4Uj2ckPS1paZXPA9A/PYfd9tW2v/bZc0nflTRZV2MA6lXlaPxcSU/b/uxz/i8iXqil\nKwC1q/Sd/UsvjO/sQN/15Ts7gMsHYQeSIOxAEoQdSIKwA0nUcSNMCmvWrGlbu//++0vnff/990vr\nH3/8cWl9y5YtpfVTp061rR0+fLh0XuTBlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCuty4dOXKk\nbW3BggWDa6SFc+fOta3t379/gJ0Ml+PHj7etPfbYY6XzTkxcvr+ixl1vQHKEHUiCsANJEHYgCcIO\nJEHYgSQIO5AE97N3qeye9VtuuaV03gMHDpTWb7755tL6rbfeWlofHR1tW7vjjjtK5z127Fhpff78\n+aX1Ki5evFha/+CDD0rrIyMjPS/7vffeK61fzufZ22HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ\ncD/7FWD27Nlta4sWLSqdd8+ePaX122+/vaeeutHp9/IPHTpUWu90/cKcOXPa1tavX18676ZNm0rr\nw6zn+9ltP2n7jO3JadPm2N5p++3isf2/NgBDoZvd+N9LWnnJtIcl7YqImyTtKl4DGGIdwx4RuyWd\nvWTyakmbi+ebJd1Tc18AatbrtfFzI+Jk8fyUpLnt3mh7TNJYj8sBUJPKN8JERJQdeIuIcUnjEgfo\ngCb1eurttO0RSSoez9TXEoB+6DXs2yWtK56vk/RsPe0A6JeO59ltPyVpVNK1kk5L2ijpGUlbJd0g\n6V1J90XEpQfxWn0Wu/Ho2r333lta37p1a2l9cnKybe2uu+4qnffs2Y7/nIdWu/PsHb+zR8TaNqUV\nlToCMFBcLgskQdiBJAg7kARhB5Ig7EAS3OKKxlx//fWl9X379lWaf82aNW1r27ZtK533csaQzUBy\nhB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2ozGdfs75uuuuK61/+OGHpfWDBw9+6Z6uZGzZgSQIO5AE\nYQeSIOxAEoQdSIKwA0kQdiAJ7mdHXy1btqxt7cUXXyydd+bMmaX10dHR0vru3btL61cq7mcHkiPs\nQBKEHUiCsANJEHYgCcIOJEHYgSS4nx19tWrVqra1TufRd+3aVVp/5ZVXeuopq45bdttP2j5je3La\ntEdtn7C9t/hr/18UwFDoZjf+95JWtpj+m4hYVPw9X29bAOrWMewRsVvS2QH0AqCPqhyge8D2m8Vu\n/ux2b7I9ZnvC9kSFZQGoqNewb5K0UNIiSScl/ardGyNiPCKWRMSSHpcFoAY9hT0iTkfEpxHxL0m/\nk7S03rYA1K2nsNsemfbye5Im270XwHDoeJ7d9lOSRiVda/u4pI2SRm0vkhSSjkr6UR97xBC76qqr\nSusrV7Y6kTPlwoULpfNu3LixtP7JJ5+U1vF5HcMeEWtbTH6iD70A6CMulwWSIOxAEoQdSIKwA0kQ\ndiAJbnFFJRs2bCitL168uG3thRdeKJ335Zdf7qkntMaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS\nYMhmlLr77rtL688880xp/aOPPmpbK7v9VZJeffXV0jpaY8hmIDnCDiRB2IEkCDuQBGEHkiDsQBKE\nHUiC+9mTu+aaa0rrjz/+eGl9xowZpfXnn28/5ifn0QeLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIO\nJMH97Fe4TufBO53rvu2220rr77zzTmm97J71TvOiNz3fz257vu2/2n7L9n7bPy6mz7G90/bbxePs\nupsGUJ9uduMvSvppRHxL0h2S1tv+lqSHJe2KiJsk7SpeAxhSHcMeEScj4vXi+TlJByTNk7Ra0ubi\nbZsl3dOvJgFU96Wujbe9QNJiSX+XNDciThalU5LmtplnTNJY7y0CqEPXR+Ntz5K0TdJPIuKf02sx\ndZSv5cG3iBiPiCURsaRSpwAq6SrstmdqKuhbIuLPxeTTtkeK+oikM/1pEUAdOu7G27akJyQdiIhf\nTyttl7RO0i+Kx2f70iEqWbhwYWm906m1Th566KHSOqfXhkc339mXSfqBpH229xbTHtFUyLfa/qGk\ndyXd158WAdShY9gj4m+SWp6kl7Si3nYA9AuXywJJEHYgCcIOJEHYgSQIO5AEPyV9Bbjxxhvb1nbs\n2FHpszds2FBaf+655yp9PgaHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ivA2Fj7X/264YYb\nKn32Sy+9VFof5E+Roxq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZLwPLly8vrT/44IMD6gSX\nM7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEN+Ozz5f0B0lzJYWk8Yj4re1HJd0v6YPirY9ExPP9\najSzO++8s7Q+a9asnj+70/jp58+f7/mzMVy6uajmoqSfRsTrtr8maY/tnUXtNxHxy/61B6Au3YzP\nflLSyeL5OdsHJM3rd2MA6vWlvrPbXiBpsaS/F5MesP2m7Sdtz24zz5jtCdsTlToFUEnXYbc9S9I2\nST+JiH9K2iRpoaRFmtry/6rVfBExHhFLImJJDf0C6FFXYbc9U1NB3xIRf5akiDgdEZ9GxL8k/U7S\n0v61CaCqjmG3bUlPSDoQEb+eNn1k2tu+J2my/vYA1KWbo/HLJP1A0j7be4tpj0haa3uRpk7HHZX0\no750iEreeOON0vqKFStK62fPnq2zHTSom6Pxf5PkFiXOqQOXEa6gA5Ig7EAShB1IgrADSRB2IAnC\nDiThQQ65a5vxfYE+i4hWp8rZsgNZEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoMesvkfkt6d9vraYtow\nGtbehrUvid56VWdvN7YrDPSimi8s3J4Y1t+mG9behrUvid56Naje2I0HkiDsQBJNh3284eWXGdbe\nhrUvid56NZDeGv3ODmBwmt6yAxgQwg4k0UjYba+0fdD2YdsPN9FDO7aP2t5ne2/T49MVY+idsT05\nbdoc2zttv108thxjr6HeHrV9olh3e22vaqi3+bb/avst2/tt/7iY3ui6K+lrIOtt4N/Zbc+QdEjS\ndyQdl/SapLUR8dZAG2nD9lFJSyKi8QswbH9b0nlJf4iI/y6mPSbpbET8ovgf5eyI+NmQ9PaopPNN\nD+NdjFY0Mn2YcUn3SPpfNbjuSvq6TwNYb01s2ZdKOhwRRyLigqQ/SVrdQB9DLyJ2S7p0SJbVkjYX\nzzdr6h/LwLXpbShExMmIeL14fk7SZ8OMN7ruSvoaiCbCPk/SsWmvj2u4xnsPSTts77E91nQzLcyN\niJPF81OS5jbZTAsdh/EepEuGGR+addfL8OdVcYDui5ZHxK2S/kfS+mJ3dSjF1HewYTp32tUw3oPS\nYpjx/2hy3fU6/HlVTYT9hKT5015/vZg2FCLiRPF4RtLTGr6hqE9/NoJu8Xim4X7+Y5iG8W41zLiG\nYN01Ofx5E2F/TdJNtr9h+6uSvi9pewN9fIHtq4sDJ7J9taTvaviGot4uaV3xfJ2kZxvs5XOGZRjv\ndsOMq+F11/jw5xEx8D9JqzR1RP4dST9vooc2fX1T0hvF3/6me5P0lKZ26z7R1LGNH0q6RtIuSW9L\n+n9Jc4aotz9K2ifpTU0Fa6Sh3pZrahf9TUl7i79VTa+7kr4Gst64XBZIggN0QBKEHUiCsANJEHYg\nCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgGgx0VBtj4V",
        "colab_type": "text"
      },
      "source": [
        "### **강사님 해설**\n",
        "#### 1. Logic 이용(OOP X)\n",
        "* Logic 짜는 방법\n",
        "\n",
        "    - 1) 모델을 10개 만들고, 각각의 모델에서 한 번씩 학습 진행. : 내가 처음에 했던 방법(비효율적).\n",
        "    - 2) 전체 그래프 node(모델 껍데기) 만들어 놓고 학습만 나중에 10번 진행.\n",
        "\n",
        "* 정확도 구하는 방법\n",
        "    - 1) 10번의 학습을 진행하고, 예측값을 구한다.\n",
        "    - 2) label 데이터와 비교한다.\n",
        "    - 3) 하나의 정확도를 도출한다.\n",
        "\n",
        "* 문제점 : **Is prediction possible?**\n",
        "    - 1) for loop을 돌면서 학습하는 과정에서 마지막 model만 남는다.\n",
        "    - 2) prediction을 진행하기 위해서는, 10개의 모델이 다 남아 있어야 한다.\n",
        "\n",
        "#### 2. OOP 이용\n",
        "* Logic을 이용해 for loop을 사용하면, 10개 모델 각각에 대해 W, b 값을 저장할 수 없다.\n",
        "* 가설 자체, W와 b를 모두 저장해야 하므로, **객체지향 방식**을 사용할 필요가 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPukvatltMJz",
        "colab_type": "text"
      },
      "source": [
        "## **강사님 코드**\n",
        "\n",
        "> Kaggle data 이용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pjeLvPNtIQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-l3XD2ptR1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz2_E9z1tTPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data loading\n",
        "\n",
        "# mnist = pd.read_csv(\"./data/DigitRecognizer/train.csv\")\n",
        "mnist = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/train.csv\")\n",
        "num_of_train = int(mnist.shape[0] * 0.8)\n",
        "train_data = mnist.loc[:num_of_train, :]\n",
        "test_data = mnist.loc[num_of_train +1:, :]\n",
        "\n",
        "train_x_data = train_data.drop(\"label\", axis = 1, inplace = False).values\n",
        "train_y_data = tf.one_hot(train_data[\"label\"].values, 10)\n",
        "sess = tf.Session()\n",
        "train_y_data = sess.run(train_y_data)\n",
        "\n",
        "test_x_data = test_data.drop(\"label\", axis = 1, inplace = False).values\n",
        "test_y_data = tf.one_hot(train_data[\"label\"].values, 10)\n",
        "test_y_data = sess.run(test_y_data)\n",
        "\n",
        "# MinMaxScaling\n",
        "train_x_data = MinMaxScaler().fit_transform(train_x_data)\n",
        "test_x_data = MinMaxScaler().fit_transform(test_x_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbPHLcSNuRgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# placeholder\n",
        "X = tf.placeholder(shape = [None, 784], dtype=tf.float32)\n",
        "Y = tf.placeholder(shape = [None, 10], dtype=tf.float32)\n",
        "dropout_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "# convolution layer\n",
        "# 입력 데이터 4차원\n",
        "x_img = tf.reshape(X, [-1,28,28,1])\n",
        "L1 = tf.layers.conv2d(inputs=x_img, filters=32,\n",
        "                     kernel_size=[3,3], padding=\"SAME\",\n",
        "                     strides=1, activation=tf.nn.relu)\n",
        "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2],\n",
        "                            padding=\"SAME\",\n",
        "                            strides=2)\n",
        "L1 = tf.layers.dropout(inputs=L1, rate=dropout_rate)\n",
        "\n",
        "L2 = tf.layers.conv2d(inputs=L1, filters=64,\n",
        "                     kernel_size=[3,3], padding=\"SAME\",\n",
        "                     strides=1, activation=tf.nn.relu)\n",
        "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2],\n",
        "                            padding=\"SAME\",\n",
        "                            strides=2)\n",
        "L2 = tf.layers.dropout(inputs=L2, rate=dropout_rate)\n",
        "\n",
        "# FC Layer = dense layer\n",
        "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
        "\n",
        "dense1 = tf.layers.dense(inputs=L2, units=256,\n",
        "                        activation=tf.nn.relu)\n",
        "dense1 = tf.layers.dropout(inputs=dense1, rate=dropout_rate)\n",
        "\n",
        "dense2 = tf.layers.dense(inputs=dense1, units=128,\n",
        "                        activation=tf.nn.relu)\n",
        "dense2 = tf.layers.dropout(inputs=dense2, rate=dropout_rate)\n",
        "\n",
        "dense3 = tf.layers.dense(inputs=dense2, units=512,\n",
        "                        activation=tf.nn.relu)\n",
        "dense3 = tf.layers.dropout(inputs=dense3, rate=dropout_rate)\n",
        "\n",
        "H = tf.layers.dense(inputs=dense3, units=10)\n",
        "\n",
        "# cost\n",
        "cost = tf.losses.softmax_cross_entropy(Y, H)\n",
        "\n",
        "# train\n",
        "train = tf.train.AdagradOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "# session, 초기화\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# ensemble\n",
        "num_of_models = 10\n",
        "result_model = np.zeros([test_x_data.shape[0], 10])\n",
        "\n",
        "for models in range(num_of_models):\n",
        "    # 학습\n",
        "    num_of_epoch = 30\n",
        "    batch_size = 100\n",
        "    \n",
        "    for step in range(num_of_epoch):\n",
        "        num_of_iter = int(train_x_data.shape[0] / batch_size)\n",
        "        cost_val = 0\n",
        "        idx = 0\n",
        "        for i in range(num_of_iter):\n",
        "            batch_x = train_x_data[idx:idx+batch_size, :]\n",
        "            batch_y = train_y_data[idx:idx+batch_size, :]\n",
        "            idx = idx + batch_size\n",
        "            _, cost_val = sess.run([train, cost], feed_dict = { X :batch_x,\n",
        "                                                               Y : batch_y,\n",
        "                                                              dropout_rate = 0.4})\n",
        "            \n",
        "        if step % 3 == 0:\n",
        "            print(\"cost : {}\".format{cost_val})\n",
        "            \n",
        "    tmp = sess.run(H, feed_dict = { X : test_x_data,\n",
        "                                  Y : test_y_data,\n",
        "                                  dropout_rate : 0})\n",
        "    \n",
        "    result_model = result_model + tmp\n",
        "    \n",
        "    # 정확도\n",
        "    predict = np.argmax(result_model, 1)\n",
        "    correct = np.equal(predict, np.argmax(test_y_data, 1))\n",
        "    accuracy = np.mean(correct)\n",
        "    print(\"정확도 : {}\".format(accuracy))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "binary classification: y data label이 0 혹은 1의 2개."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# logistic model의 의미\n",
    "# Logistic Regression을 그림으로 알아보자.\n",
    "# 결국, Titanic 예제 같은 것을 하는 목적은, 가설을 얻어내는 것.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn\n",
    "# warnings 내부 모듈 : 경고메시지 뜨지 않게 하려고\n",
    "# scikitlearn에서 linear model 활용\n",
    "# mglearn : 처음 쓰는 모듈 -> 설치 안 되어 있음 -> module not found error -> anaconda prompt -> activate cpu env -> pip install mglearn\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "# warning 내부모듈에서 warning 메시지 무시하도록.\n",
    "# warning 출력 배제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 3.5901057720184326\n",
      "cost 값은 : 0.28111472725868225\n",
      "cost 값은 : 0.2499435693025589\n",
      "cost 값은 : 0.2418675422668457\n",
      "cost 값은 : 0.23877932131290436\n",
      "cost 값은 : 0.23727622628211975\n",
      "cost 값은 : 0.23637381196022034\n",
      "cost 값은 : 0.23572272062301636\n",
      "cost 값은 : 0.23518382012844086\n",
      "cost 값은 : 0.2346976399421692\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPwUlEQVR4nO3d309U577H8c8UBlnHGJBSq4D8nCMhItFqk5P0btuIyY6J8aJ/wP4Das4FyTZN3KY3NvFix/4BOzk358K9Y8huiWUn9abd5qRhd1I9Oyk9DFZlgGhtwdYOZYB1LmavgTUsKMOw1rN+vF9JQ3iG4gPoZx6e5/l+J2XbtgAAwXvF9AQAIKkIYAAwhAAGAEMIYAAwhAAGAEMIYAAwpL6aD25tbbW7u7t9mgoAxE9ra6vGx8fHbds+X/lYVQHc3d2tiYmJvZsZACRAKpVq9RpnCwIADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAjgJ7t+S/jgoXWsuvb1/y/SMAKjKXhCIoPu3pI/elYqF0vuLT0rvS9LQO+bmBYAVcOx9+v56+DqKhdI4AKMI4LhbnKluHEBgCOC4a+qobhxAYAjguDt7VUpb7rG0VRoHYBQBHHdD70gXPpSajkpKld5e+JADOCAEuAWRBEPvELhACLECBgBDCGAAwaAgaBO2IAD4j4IgT6yAHUl9dk7q141gURDkiRWwlJxn5/u3Sn/hF2dK94D//Zz01X9v/rof/4/0f39b/7izV+P1fUDwKAjyxApYSsazs/Mks/hEkl16O/En76974k/uj/voXVbGqA0FQZ4IYCkZz85eTzKyt/jgivG4PRkheBQEeSKApWQ8O9f6ZBKnJyMEj4IgT+wBS6Vn4Y17wFL8np2bOv61rVApJfeKt/L9Df8/UAsKgjZhBSwl49l5q18Bz/zO/XWf+R2/KgIBYQXsiPuzs/O1bbwFsdXths7/2NnHAahJyra3OojZ7MyZM/bExISP0wGA+EmlUv+wbftM5Xi0tiAoGgAQI9HZgvCrWKKyOIFftwEEJDorYD+KJbyKEyg6ABCQ6ASwH8USSaiAAxBa0QlgP4olklABByC0ohPAfpQyJqECDkBoRSeA/SiWoD4diKeI3JiKzi0Iae+LJaopTgAQDRFqLxutAPZD3Cvg4o5rhKi03eF6yP5uEMCIrgitdBCgCB2uR2cPGKjENUJ4idDhOgEchIgcCEROhFY6CFCEDtcJYL9RbeefCK10EKAItZdlD9hvEToQiJwkNNLH7kTkcJ0VsN/4Ndk/EVrpAF5YAfttq5cC4tfkvRGRlQ7ghRWw3yJ0ILArHDACuxabFfBoNq8b45OaXSiordnSyHC/Lp5qNz2teFfbcQ8XqEksXpJoNJvXldsPVCiulsesdJ2uXzoRjhCOqz8ObrG9clT6z/8Nfj5ASMXjJYm2cGN80hW+klQorurG+KShGSUEB4xATWIRwLMLharGsUe4hwvUJBYB3NZsVTWOPRL3A0bAZ7EI4JHhflnpOteYla7TyHC/oRklBPdwgZrE4haEc9AWylsQccc9XGDXYhHAUimECVwAURKLLQgAiCICOMLGpsd07i/nNPRfQzr3l3Mamx4zPSUAVYjNFkTSjE2P6dq9a1paXZIkzb2c07V71yRJv+39rcGZAdgpVsARdfPLm+XwdSytLunmlzcNzQhAtaoK4MXFRX399df65Zdf/JoPdmj+5XxV4wDCp6otiGfPnmlkZESpVEpHjx5VJpNRX1+fMpmMent71djY6Nc8UeHw/sOaeznnOQ4gGqoK4O7ubr333nvK5XKamppSNpvV3bt3JUmpVErt7e3q6+tzhfL+/ft9mXjSXX7jsmsPWJIa6xp1+Y3LBmcFoBo1d0P7/vvvy4HsvH3+/Hn58SNHjpQD2QnnAwcO7NkXkGRj02O6+eVNzb+c1+H9h3X5jcscwAEhtFU3NF/aUS4uLpYD2Qnlp0+flh8/dOiQMpmMK5Sbmpp2PA8AiJJAA9jLjz/+uGmlPD+/fmDU2trqWilnMhkdPHhwV38WAITJVgEc2D3gAwcO6OTJkzp58mR57OXLl65Vci6X0xdffCHnSaGlpcW1p9zX16dXX31VqVQqqGkDgG+MFmLs379fQ0NDGhoaKo8VCoVyKDvBPDExUQ7lpqYm19ZFJpPRa6+9RigDiJzQVcJZlqXBwUENDg6Wx5aWlvTw4UPXSjmbzWptbU1SaXVdedB3+PBhQhlAqIUugL00NjZqYGBAAwMD5bHl5WV9++23mpqaKofy6OioVlZWJJVW15XbF21tbYQygNCIRAB7aWho0LFjx3Ts2LHy2MrKSjmUnS2Mjz/+WMViUVIpyCsP+trb2/XKK1RkAwheZAPYS319ffl6m2NlZUVPnjxxhfKdO3e0vLwsSdq3b596e3tdq+WOjg7V18fqWwMghGLxsvTVWl1d1czMjGtPeXp6WktLpaqyhoYGdXV1lcM8k8mos7OTUAawK8bvAYedbdvK5/OuUM7lcvr5558llVbXTig7K+Wuri41NDQYnjmAsCOAd8G2bc3Pz7uKR3K5nH766SdJUl1dnTo7O137yj09Pdq3b5/hmQMIEwJ4j9i2radPn26q6nvx4oUk0SkOwCYEsI9s29bz5883rZR/+OEHSXSKA5KOADZgJ53iKlfKdIoD4sd4L4gkamlpUUtLi958883yWGWnuMnJSX322Wflx19//fVNVX10igPiiRVwCFR2isvlcpqbW3+1CzrFAdHGCjjE6BQHJBMBHFJ0igPijwCOEDrFAfFCAEfcr3WKc4KZTnFA+BDAMeTVKa5YLOrRo0eulTKd4gCzuAWRYE6nOCeUp6am9PDhw207xR09elR1dXWGZw5EC4UY2JHV1VXl83nX9kVlp7ju7m7Xarmrq4tOccA2CGDsGp3igNoQwNhTdIoDdo4Ahu82dorbGMqLi4uSNneK6+vrU29vryzLMjxzwF8EMIxwOsVVNiWiUxyShABGqFTTKc75j05xiCp6QSBUdtMp7tChQ66DPjrFIepYASPUqu0U19fXp5aWFoMzBjZjBYxIolMc4owARuRs1SluenratadMpziEHQGMWLAsS8ePH9fx48fLY06nuI3bF3SKQ5gQwIgtOsUh7AhgJMqvdYpzQplOcQgCAYzES6fTymQyymQy5bHKTnG5XE537txxdYrr6elxhXJHRwdNiVAVrqEBO7S2tlYO5Z10istkMurs7CSUQSUc4Ac6xWEnCGAgIHSKQyUCOERGs3ndGJ/U7EJBbc2WRob7dfFUu+lpwUdeneKmpqb04sULSeud4iqvxTU2NhqeOfYCARwSo9m8rtx+oEJxtTxmpet0/dIJQti0+7ekT9+XFmekpg7p7FVp6B3f/jinU9zGrQs6xcUTARwSb31wV/mFwqbx9mZLf//9bwzMCJJK4fvRu1Jxw88mbUkXPvQ1hL04neI2bl9899135cePHDmyaaVMp7hwoxdESMx6hO924wjIp++7w1cqvf/p+4EH8E46xX3zzTf6/PPPy4/TKS6aCOCAtTVbnivgtmZeFcKoxZnqxgPW1NSk06dP6/Tp0+Uxr05x9+7dKz9e2Skuk8no4MGDJqaPLRDAARsZ7vfcAx4Z7jc4K6ipQ1p84j0eUnSKiz4COGDOQRu3IELm7FXvPeCzV83NaRfoFBctHMIBjoBvQZjk1Snu8ePHdIrzCbcgAGyrslNcLpfTo0eP6BS3B7gFAWBbtXSK2xjKHR0ddIrbIQIYwJa26xS3cU/5k08+oVPcLrAFAaBmq6urmpmZ+dVOcRv3lLu6uhITyuwBAwjU2tqaZmdn6RQnAhhACCS1UxwBDCCUbNvWs2fPXKG8Xae4TCajnp4eWVZ0qkcJYACRUdkpznnr1SnOWSmHuVMcAQwg8qLaKY57wPANDeYRlLh1imMFjJrQYB5h5NUpbm5urvx40J3i2IKAL2gwj6jw6hQ3OzsbSKc4tiDgCxrMIyq26hTnhLKJTnEEMGpCg3lEmWVZGhwc1ODgYHnM6RS3caWczWZ96RRHAKMmNJhH3DQ2NmpgYEADAwPlseXlZT18+NDVV3l0dNSzU5wTzjvpFEcAoyY0mEcSNDQ0qL+/X/396wuLYrGox48flwtHcrmcZ6e48+fPb/l5CWDU7OKpdgIXiZNOp8sr3uHhYUnrneI2bl84vS+8EMAAsEfq6+vV09Ojnp4evf3227/+8QHMKRIoJgAQNAJYm4sJ8gsFXbn9QJIIYQC+4XVDVDpA2niKL0mF4qpujE8amhGAJGAFrGCKCdjiAFCJFbC2LhrYq2KC0WxeI3/+SvmFgmyVtjhG/vyVRrP5Pfn8AKKJAFapmMBK17nG9rKY4Npf/6nimrvnRnHN1rW//nNPPj+AaGILQv4XEywUilWNA0gGAvhfKCYAEDS2IAJw8N/SVY0DSAYCOAB/uHBc6Tp3U450XUp/uHDc0IwAc0azeb31wV31/H5Mb31wN9GH0bHeggjL1S8a1gAlFD25xTaAw/aDZo8Z2L7oKYn/PmK7BUF1GxA+vIKKW2wDmB80ED5+Fz1FTWwDmB80ED5+Fz1FTWwDmB80ED4XT7Xr+qUTam+2lFLp1bOvXzqRyP1fKcaHcNw8AMKJA+l1sQ1giR80gHCL7RYEAIRdrFfASLawFOIAWyGAEUthK8QBvLAFgViiEAdRQAAjlijEQRQQwIglCnEQBQQwYolCHEQBh3CIJQpxEAUEMGKLQhyEHVsQAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhhDAAGAIAQwAhtSbngAAf41m87oxPqnZhYLami2NDPfr4ql209OCCGAEjDAI1mg2ryu3H6hQXJUk5RcKunL7gSTxfQ8BtiAQGCcM8gsF2VoPg9Fs3vTUYuvG+GQ5fB2F4qpujE8amhE2YgWMmu10VbtdGLAa88fsQqGqcQSLFTBqUs2qljAIXluzVdU4gkUAoybV/IpLGARvZLhfVrrONWal6zQy3G9oRtiIAEZNqlnVEgbBu3iqXdcvnVB7s6WUpPZmS9cvnWDLJyTYA0ZN2pot5T3C1mtV6/yj5xZEsC6eaud7HFIEMGoyMtzvuuYkbb+qJQyAdQQwasKqFtg9Ahg1Y1UL7A6HcABgCAEMAIYQwABgCHvAEUADGyCeCOCQo5sVEF9sQYQc3ayA+CKAQ44GNkB8EcAhRwMbIL4I4JCjgQ0QXxzChRylvkB8EcARQKkvEE9sQQCAIQQwABhCAAOAIQQwABhCAAOAIQQwABhCAAOAIQQwABhCAAOAIQQwABiSsm175x+cSj2T9Mi/6QBA7HwnSbZtn698oKoABgDsHbYgAMAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcAQAhgADCGAAcCQ/wfLYv5D7XtgjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mglearn의 기본 data set을 이용해 그림을 그린다.\n",
    "# mglearn의 dataset 중 make_forge라는 data set\n",
    "\n",
    "# 1. data load\n",
    "x, y = mglearn.datasets.make_forge()\n",
    "\n",
    "# 2. data 확인\n",
    "\n",
    "x   # x data는 2차원 numpy array\n",
    "y   # y data는 0, 1, 0, 1, ...\n",
    "\n",
    "# 데이터를 살펴본 결과, 입력 파라미터가 2개이고(2차원), label이 0 혹은 1로 떨어지는 logistic model.\n",
    "\n",
    "# 문제를 단순화시켜서 x축 data만 그림으로 살펴보자.\n",
    "\n",
    "# y label에 대해 각각의 x가 어떻게 분포되어 있는지를 확인하기 위함.\n",
    "\n",
    "# 산점도(scatter) 그리기.\n",
    "# y값이 0인 x를 추출해서, x의 첫 번째 column을 x축으로, x의 두 번째 column을 y축으로 그린다. -> column 간 관계 파악.\n",
    "# label이 각각 0과 1인 x 데이터만 출력 : 2번째 행, 4번째 행, 5번째 행, ...\n",
    "# boolean mask 사용\n",
    "y == 0   # broadcasting되어서 boolean mask 결과로 나옴. -> x 행에 집어넣으면, True에 해당하는 data만 추출.\n",
    "blue = x[y==0]  # 파란색 점 찍히는 애들\n",
    "plt.scatter(blue[:,0], blue[:,1])\n",
    "# blue[:,0] -> 모든 행에 대해서 첫 번째 열\n",
    "orange = x[y==1]   # 주황색 점 찍히는 애들\n",
    "plt.scatter(orange[:,0], orange[:,1])\n",
    "\n",
    "# 파란 점들: y가 0일 때, x축 data가 어떻게 분포되어 있나.\n",
    "# 주황 점들: y가 1일 때, x축 data가 어떻게 분포되어 있나.\n",
    "\n",
    "# 3. machine learning(Logistic Regression)\n",
    "# 데이터 넣어서 학습 -> 테스트 통해 정확도 측정 -> 예측.\n",
    "\n",
    "# 원래는 train data set, test data set 나눠서 accuracy 측정해야 하는데, 지금은 생략.\n",
    "\n",
    "# 3-1. 학습 : train data set\n",
    "\n",
    "# 1) train data set\n",
    "# x는 그냥 넣어도 되지만, y는 1차원이라서 그냥 넣으면 안 된다.\n",
    "train_x_data = x\n",
    "train_y_data = y.reshape([-1,1])\n",
    "\n",
    "# 2) placeholder\n",
    "X = tf.placeholder(shape = [None, 2], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "# 3) weight, bias\n",
    "# 초기 값으로 random 값을 주고, 학습을 통해 최적화되며 W와 b가 변해 간다.\n",
    "# 원래는 랜덤 값 외에 다른 것도 줄 수 있지만.\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# 4) H, 가설 설정 -> 머신러닝의 목적: 가설 완성.\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# 5) cost function\n",
    "# tf.nn.sigmoid_cross_entropy_with_logits : 인자 2개로, 첫 번째 인자(logits)로 logit, 두 번째 인자(labels)로 Y. \n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                             labels = Y))\n",
    "\n",
    "# 6) train node, optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "# train = optimizer.minimize(cost)\n",
    "# 한 줄로 표현하기\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# 7) session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8) 학습 진행\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = {X : train_x_data,\n",
    "                                                      Y: train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))\n",
    "\n",
    "# 3-2. 정확도(accuracy) 측정 : test data set\n",
    "# 원래는 test data set을 가지고 정확도 측정해야 함.\n",
    "# 학습의 결과가 만족스러운지 확인하기 위함.\n",
    "# 지금 단계에서는 생략. 그냥 학습만 진행.\n",
    "# 정확도 측정에서 95% 이상 나오면 사용할 만한 모델. : 업무/실생활에서 적용할 수 있음.\n",
    "\n",
    "# 3-3. 예측(prediction)\n",
    "\n",
    "# H를 실행해서 예측하는 게 목적.\n",
    "result = sess.run(H, feed_dict = {X : [[9,4]]})\n",
    "result\n",
    "# X에 아무 거나 넣어서 예측.\n",
    "# X는 placeholder 형태이므로 shape 맞춰서 넣어야 함.\n",
    "# result 찍어보니까 0.8 정도 나옴 : 1에 가까움.\n",
    "\n",
    "# 그래프로 그려 보면, 1에 가깝게 나온다.\n",
    "plt.scatter(9,4)\n",
    "\n",
    "# 4. sklearn 활용\n",
    "\n",
    "# 4-1. 학습\n",
    "# 한 번에 학습이 끝남.\n",
    "model = LogisticRegression()\n",
    "myModel = model.fit(x,y) # logistic model 학습\n",
    "\n",
    "# 4-2. 예측\n",
    "# data를 넣어줘야 예측이 가능하니까, x쪽에 데이터 넣어준다.\n",
    "print(myModel.predict([[9,4]]))\n",
    "# 결과값이 1이 나옴.\n",
    "# 이전의 모델에서는 0.8 정도 떨어져서, 0.5보다 크니까 1로 간주한다고 이해했지만,\n",
    "# sklearn에서 model 이용해서 바로 학습 진행하고 예측하면, 1이라는 결과값 도출.\n",
    "\n",
    "# 4-3. mglearn 이용해 그래프 그리기.\n",
    "# mglearn, plots의 plot_2d_separator 활용해 내가 만든 모델을 그림으로 표현할 수 있음.\n",
    "# tensorflow로 만든 모델은 아니지만, sklearn으로 만든 모델이어도 그림으로 그린다.\n",
    "mglearn.plots.plot_2d_separator(myModel, x, fill = False, eps = 0.5, alpha = 0.7)\n",
    "# 중요한 인자 : myModel, x\n",
    "# myModel의 x data 이용해 그림을 그릴 것이다.\n",
    "# alpha : 투명도(1일수록 진함)\n",
    "# eps : 그래프가 크게 보이는데, 그 scale을 축소해서 보기 좋게 하려고.\n",
    "# x : x data 이용한다.\n",
    "\n",
    "# 그림 그려보니까, 선이 그려진다.\n",
    "# 결국 logistic model을 만든다는 것은, 저 선을 그린다는 것.\n",
    "# 내가 알고 싶은 데이터가 선을 기준으로 무슨 영역에 위치하는지 알아내는 것.\n",
    "\n",
    "# linear model은 주어진 데이터를 가장 잘 표현하는 직선을 만드는 것.\n",
    "# logistic은 0과 1을 구분하는 가장 적절한 선을 구하는 것.\n",
    "# 두 개의 분류를 가로지르는 적절한 선을 가로지르는 것.\n",
    "# 결국 logistic model을 만드는 것은 저 선이 무엇인지, 어디에 있는지 알아낸다.\n",
    "# 내가 알고 싶은 데이터가 어느 영역에 있는지 표현.\n",
    "\n",
    "# 만약 x축 데이터가 3개라면, 3차원 공간의 그래프가 될 것이고, logistic model은 평면이 된다.\n",
    "\n",
    "# hyperplan이라고 불리는 선/면/공간을 구하는 model이 logistic model.\n",
    "# 군집(0, 1)이 있는데, 그걸 가로지르는 hyperplane(경계)이 어디인지 알아내는 것.\n",
    "\n",
    "# 그렇다고 저 선이 0.5를 나타내는 것은 아님.\n",
    "# 0.5라는 값은 임의적으로 잡은 값 : 둘 중에 하나로 선택해야 하니까 50%를 기준으로.\n",
    "# 0.8이라는 값은, 선을 기준으로 위쪽 영역에 얼마나 가까운지를 수치로 나타낸 값.\n",
    "\n",
    "# 그런데, 그림을 그려보니까 파란색, 주황색이 완전하게 구분되지 않는다.\n",
    "# 과적합의 문제가 있어서 실제로 안 좋은 결과값을 도출할 수 있다.\n",
    "# 손필기!\n",
    "# 약간의 오류가 있어 보이는 것 같지만, 실제 data 예측에서는 훨씬 더 좋은 hyperplane.\n",
    "# overfitting 피하는 방법: 딥러닝에서!\n",
    "\n",
    "\n",
    "# tensorflow 가지고 예측을 하거나, logistic으로 만든 model을 가지고 예측을 하거나, \n",
    "# 결국 [[9,4]]가 어느 쪽에 있는지를 보고 그게 해당 선을 기준으로 어디에 있는지 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model을 multinomial로 확장.\n",
    "# tensorflow 등 머신러닝에서 많이 쓰이는 사례\n",
    "\n",
    "# Multinomial classification\n",
    "# y data label이 여러 개.\n",
    "\n",
    "# hyperplane이 여러 개\n",
    "# 각 영역에 대해 가까울 확률이 얼마인지\n",
    "# 그래프가 바뀌기 때문에 가설도 바뀌고, 모델도 바뀌고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data는 시험 성적과 출석 점수, Y data는 학점(0, 1이 아니라 다양함).\n",
    "# Y label이 2개 초과의, 정해져 있는 범주에서 나온다.\n",
    "\n",
    "# 시험점수 출석점수 성적\n",
    "#   10       5       A\n",
    "#   9        5       A\n",
    "#   5        1       B\n",
    "#   4        2       B\n",
    "#   1        3       C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25b5d565550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력으로 들어갈 X data : 시험점수, 출석점수 -> numpy array로 표현.\n",
    "\n",
    "x_data = np.array([[10,5],\n",
    "                  [9,5],\n",
    "                  [5,1],\n",
    "                  [4,2],\n",
    "                  [1,3]])\n",
    "# 2차원 numpy array\n",
    "\n",
    "y_data = np.array([[\"A\"],\n",
    "                  [\"A\"],\n",
    "                  [\"B\"],\n",
    "                  [\"B\"],\n",
    "                  [\"C\"]])\n",
    "# y label이 문자열이므로 학습이 되지 않음.\n",
    "\n",
    "# 자료 구조 확인\n",
    "\n",
    "# data를 따로 확인해 보자.\n",
    "# scatter 그리기\n",
    "plt.scatter(x_data[0:2,0], x_data[0:2, 1]) # A학점 받은 x data 구조(시험점수, 출석점수)\n",
    "plt.scatter(x_data[2:4,0], x_data[2:4, 1]) # B학점 받은 y data 구조(시험점수, 출석점수)\n",
    "plt.scatter(x_data[4,0], x_data[4, 1])\n",
    "\n",
    "# x_data의 0, 1행에 대해서 0열이므로 10, 9 + x_data의 0, 1행에 대해서 1열이므로 5, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예시\n",
    "3번의 퀴즈, 출석 점수를 통해 성적을 예측.\n",
    "\n",
    "           x data                   label          one-hot encoding\n",
    "퀴즈1    퀴즈2   퀴즈3    출석      성적       A      B     C\n",
    "10         7       8        5        A         1\n",
    "8          8       9        4        A         1\n",
    "7          8       2        3        B                1\n",
    "6          3       9        3        B                1\n",
    "7          5       7        4        B                1\n",
    "3          5       6        2        C                      1\n",
    "2          6       3        1        C                      1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1]]\n",
      "cost 값은 : 11.230758666992188\n",
      "cost 값은 : 1.1732550859451294\n",
      "cost 값은 : 0.9902771711349487\n",
      "cost 값은 : 0.6860259175300598\n",
      "cost 값은 : 0.5618454813957214\n",
      "cost 값은 : 0.5118224024772644\n",
      "cost 값은 : 0.47368839383125305\n",
      "cost 값은 : 0.05306902900338173\n",
      "cost 값은 : 0.047983258962631226\n",
      "cost 값은 : 0.04433310404419899\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 학습(train) -> 정확도(test) -> 예측(prediction) : 정확도 생략.\n",
    "\n",
    "# 1. 학습\n",
    "\n",
    "# 1-1. training data set : numpy array\n",
    "\n",
    "# x data : 세 번의 퀴즈와 출석\n",
    "train_x_data = [[10,7,8,5],\n",
    "                [8,8,9,4],\n",
    "                [7,8,2,3],\n",
    "                [6,3,9,3],\n",
    "                [7,5,7,4],\n",
    "                [3,5,6,2],\n",
    "                [2,4,3,1]]\n",
    "\n",
    "# y data : y쪽 label -> one-hot encoding\n",
    "train_y_data = [[1,0,0],\n",
    "                [1,0,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,0,1],\n",
    "                [0,0,1]]\n",
    "print(train_y_data)\n",
    "\n",
    "# 1-2. placeholder\n",
    "# Y가 one- hot encoding으로 변하니까, shape에 주의.\n",
    "X = tf.placeholder(shape = [None, 4], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
    "\n",
    "# 1-3. W, bias\n",
    "# weight 행렬의 크기에 주의 : X, Y 보고 빠르게 구할 수 있음.\n",
    "# logistic 3개 모였으니까(A, B, C) bias 1차원으로 3개\n",
    "# bias : 분류의 개수\n",
    "W = tf.Variable(tf.random_normal([4,3]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name = \"bias\")\n",
    "\n",
    "# 1-4. hypothesis\n",
    "# logit은 동일하게 행렬곱\n",
    "# 가설 함수에서 sigmoid하면 각각의 가설에 대해 확률이 나온다. sigmoid 안 된다.\n",
    "# 전체 확률값의 합이 1이 되게 구하기 위해 softmax.\n",
    "# softmax : tensorflow가 제공하는, 확률값을 구해주기 위한 함수.\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# 1-5. cost function\n",
    "# multinomial에서는 hypothesis가 바뀌니까 cost함수도 따라서 바뀌어야 함.\n",
    "# tensorflow 라이브러리가 제공해준다.\n",
    "# softmax cross entropy version2를 사용해야 한다! 인자는 binomial과 동일함\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# 1-6. train\n",
    "# 동일 : gradient descent 사용, learning rate도 그대로 사용.\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 1-6. 실행할 준비 : session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 1-7. 학습\n",
    "# learning_rate 0.1 줬을 때 cost값이 제일 작아지는데?\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = { X : train_x_data,\n",
    "                                                      Y : train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))\n",
    "\n",
    "# 학습 끝\n",
    "# 데이터 크기 매우 작기 때문에, minmax scaler 등 작업 거치지 않아도 raw data로 학습 가능.\n",
    "\n",
    "# 2. 정확도 측정\n",
    "\n",
    "# 로지스틱에서의 정확도 측정\n",
    "# predict = tf.cast(H>0.5, dtype = tf.float32)\n",
    "# 결과로 나오는 H가 true일 확률로 나오기 때문에, 0.5를 기준으로 boolean을 추출하고 실수로 casting할 수 있었음.\n",
    "\n",
    "# MULTINOMIAL의 정확도 측정\n",
    "# x 데이터만주면 됨. \n",
    "sess.run(H, feed_dict = { X : [[10,8,9,5]]})\n",
    "# 값이 3개 나옴. 10의  -1승으로 a일 확률이 제일 크게 나옴.\n",
    "\n",
    "# 예측해서 나온 A라는 학점이 y측 label과 같은지 봐야 함. 그걸 가지고 정확도 측정.\n",
    "predict = tf.argmax(H, axis = 1)  # 가장 큰 값의 index 번호 return\n",
    "# argmax : 특정 방향으로 가장 큰 값의 index 번호 return\n",
    "# axis = 0 : 세로(행) 방향, axis = 1 : 가로(열) 방향\n",
    "\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis = 1))\n",
    "# 비교할 것인데, 입력한 정보(Y측 label)에서 가로 방향으로 가장 큰 값이 몇 번째에 있는지 index 번호 찾아서\n",
    "# 몇 번째에 있는지 비교. -> tensorflow의 equal을 기준으로.\n",
    "# logistic은 0.5를 기준으로 크냐작냐를기준으로 비교 했는데 여기서는 다르다.\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype = tf.float32))\n",
    "# correct를 cast하고 \n",
    "\n",
    "# test data 밀어넣어 주면서 accuracy 측정\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                feed_dict = {X: train_x_data,\n",
    "                                            Y: train_y_data})))\n",
    "# 예측 정확도와 별개로, 위와 같이 학습한 데이터를 가지고 테스트한다면 정확도 거의 1에 가깝게 나옴,\n",
    "# 특정 데이터를 가지고 학습했는데, 그 학습 데이터를 그대로 테스트하는 상황.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI 예제\n",
    "1. 혼자 푼 파일\n",
    "2. 정답 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 : BMI 측정\n",
    "# BMI 데이터를 학습한 후 자신의 키와 몸무게를 넣어서 상태 확인.\n",
    "# 실측 데이터 : 표준 미만, 표준, 표준 초과의 3개 label\n",
    "# bmi.csv 찾아서 multinmial 문제 학습!\n",
    "\n",
    "# one hot encoding, minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI 예제 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x25b5e6db518>,\n",
       "  <matplotlib.lines.Line2D at 0x25b5e6db860>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x25b5e6dbba8>,\n",
       "  <matplotlib.lines.Line2D at 0x25b5e6dbef0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x25b5e6bbb70>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x25b5e6e5278>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x25b5e6e55c0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Data 준비 및 확인\n",
    "data_df = pd.read_csv(\"./data/bmi.csv\", skiprows = 3)\n",
    "\n",
    "# 결측치 확인 : 없음.\n",
    "data_df.isnull().sum()\n",
    "\n",
    "# 이상치 확인\n",
    "plt.boxplot(data_df[\"height\"]) # 이상치 없음\n",
    "plt.boxplot(data_df[\"weight\"]) # 이상치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MinMaxScaler' object has no attribute 'data_max_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b95ef96b7ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# scaler 하나의 변수로 저장해 놓기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_max_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MinMaxScaler' object has no attribute 'data_max_'"
     ]
    }
   ],
   "source": [
    "# 1. data 준비\n",
    "\n",
    "# train, test data 나눌 기준 행 넘버\n",
    "split_num = int(data_df.shape[0] * 0.8)\n",
    "\n",
    "# x_data, y_data 준비\n",
    "# 행 들고 오고, 열은 뒤에 한 번에 fancy indexing 줘도 된다.\n",
    "# 들고올 때 한 번에 정규화하자.\n",
    "train_x_data = data_df.loc[:split_num, [\"height\", \"weight\"]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# scaler 하나의 변수로 저장해 놓기\n",
    "MinMaxScaler().data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "(16000, 3)\n",
      "(4000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1. data 준비\n",
    "\n",
    "# train, test data 나눌 기준 행 넘버\n",
    "split_num = int(data_df.shape[0] * 0.8)\n",
    "\n",
    "# scaler 변수로 저장\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 1-1. x_data\n",
    "# 1) 행 들고 오고, 열은 뒤에 한 번에 fancy indexing 줘도 된다.\n",
    "# 2) 들고 올 때 한 번에 정규화한다.\n",
    "x_data = scaler.fit_transform(data_df.loc[:split_num, [\"height\", \"weight\"]])\n",
    "## MinMaxScaler().fit_transform 이라는 함수\n",
    "## fit_transform 두 가지 역할 동시에 한다.\n",
    "## fit : minmax 할 data 들고와\n",
    "## transform : 변환해\n",
    "\n",
    "# 3) train, test용으로 나누기\n",
    "train_x_data = x_data[:split_num]\n",
    "print(train_x_data.shape)\n",
    "# x_data가 주체임 : min max scaler, fit transform 통과해서 들고온다 -> 정규화되면서 numpy array가 된다\n",
    "# -> numpy array에서는 뒤에가 exclusive\n",
    "test_x_data = x_data[split_num:]\n",
    "\n",
    "# 1-2. y_data  생성 \n",
    "\n",
    "# one_hot encoding 필요\n",
    "# - pandas.get_dummies()\n",
    "# - tensorflow.one_hot()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 주의할 것 : 데이터의 개수\n",
    "sess.run(tf.one_hot(data_df.loc[:split_num, \"label\"], 3)).shape\n",
    "# data_df.loc[:split_num, \"label\"] : label column만 split_num까지 행을 들고 온다.\n",
    "# tf.one_hot의 인자 : 분할할 데이터(data_df.loc[:split_num, \"label\"]), 그것을 몇 개로 분할할 것인지(3)\n",
    "# sess.run(tf.one_hot(data_df.loc[:split_num, \"label\"], 3)) : 16001개\n",
    "# data_df : pandas의 dataframe -> numpy가 아님 -> data frame에서 loc 사용해서 행 가져오면 뒤에 inclusive\n",
    "# 따라서 one_hot 사용하려면 -1 해줘야 데이터의 개수가 일치한다\n",
    "\n",
    "train_y_data = sess.run(tf.one_hot(data_df.loc[:split_num-1, \"label\"], 3))\n",
    "print(train_y_data)\n",
    "print(train_y_data.shape)\n",
    "# -1 : 데이터 개수 일치시키기 위해\n",
    "test_y_data = sess.run(tf.one_hot(data_df.loc[split_num:, \"label\"], 3))\n",
    "print(test_y_data.shape)\n",
    "# test 에서는 split이 앞에 있으니까 inclusive이므로 -1 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 1.448047161102295\n",
      "cost 값은 : 0.3605087101459503\n",
      "cost 값은 : 0.28349339962005615\n",
      "cost 값은 : 0.24528183043003082\n",
      "cost 값은 : 0.2211015522480011\n",
      "cost 값은 : 0.2039448618888855\n",
      "cost 값은 : 0.1909186989068985\n",
      "cost 값은 : 0.18057306110858917\n",
      "cost 값은 : 0.17208760976791382\n",
      "cost 값은 : 0.16495674848556519\n"
     ]
    }
   ],
   "source": [
    "# 2. 학습\n",
    "\n",
    "# 2-1. 데이터 셋 준비\n",
    "train_x_data\n",
    "train_y_data\n",
    "\n",
    "# 2-2. placeholder\n",
    "X = tf.placeholder(shape = [None, 2], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
    "\n",
    "# 2-3. weight, bias\n",
    "W = tf.Variable(tf.random_normal([2,3]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name = \"bias\")\n",
    "\n",
    "# 2-4. hypothesis\n",
    "logit = tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# 2-5. cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                labels = Y))\n",
    "\n",
    "# 2-6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 2-7. 준비: session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 2-8. 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = { X : train_x_data,\n",
    "                                                        Y : train_y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.30149999260902405\n"
     ]
    }
   ],
   "source": [
    "# 3. 정확도 : 잘못됐다.\n",
    "predict = tf.argmax(H, axis = 1) \n",
    "correct = tf.equal(predict, tf.argmax(Y, axis = 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                feed_dict = {X: test_x_data,\n",
    "                                            Y: test_y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. prediction\n",
    "prediction_data = scaler.transform([[180, 60]])\n",
    "prediction_data\n",
    "# sess.run(H, feed_dict = {X: prediction_data}) : 이렇게 나오면 너무 보기 안 좋으니...\n",
    "sess.run(tf.argmax(H,1), feed_dict = {X: prediction_data})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

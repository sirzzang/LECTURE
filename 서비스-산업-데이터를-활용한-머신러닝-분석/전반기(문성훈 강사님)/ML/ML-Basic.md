# 데이터 분석을 위한 통계적 기법



 통계적 기법을 이용한 데이터 분석은 크게 2가지로 분류된다.

- **Descriptive** Statistics: 수집한 데이터의 요약, 묘사, 설명 등.
- **Inferential** Statistics: 과거의 데이터를 학습하여 앞으로의 일을 예측. 머신러닝, 딥러닝과 밀접한 연관.







## 1. 기술통계

 

 수집한 데이터를 기술하는 데 사용하는 통계 기법.



### 1.1. **집중화** 경향에 따른 분석



 데이터가 어디에 몰려 있는지 분석 => 평균, 중앙값, 최빈값 등.



### 1.2. **분산도**에 따른 경향 분석

데이터가 얼마나 퍼져 있는지 => 표준편차, 사분위값 등. *예) 우리나라 1인당 국민소득을 이용한 소득 불균형*





## 2. 추리(추론)통계

 수집한 데이터를 기반으로 어떠한 사실을 예측(추론)하고, 검정하는 데 사용하는 통계 기법. *통계적 가설 검정**(Statistical Hypothesis Testing): 표본을 근거로 모집단에 대한 **맞는지** 통계적으로 검정





### 2.1. 회귀분석(regression)



**regression model**을 근거로, 내가 가진 데이터를 이용해서 미래를 예측. 통계학에서 상당한 비중을 차지하는 자료 분석 방법. machine learning의 **지도학습**과 연관성이 높음.



#### 2.1.1. 출발점

* 가정: 수집/관찰한 데이터가 특정한 경향성을 가지고 있을 것이다.

  *예) 여름 온도와 코카콜라 판매량*

* 데이터의 변수들(온도, 판매량 등) 사이에서 나타나는 경향성, 의존성 등을 수학적으로 판별하고자 함.

* 수학적으로 가장 적합한 **model**을 설정할 수 있다면, 그것에 기초하여 앞으로 발생할 일(미래의 데이터)을 **예측**할 수 있음.



#### 2.1.2. 머신러닝

 

machine learning은 소프트웨어(프로그램).



* 출현 배경: Explicit Program의 한계

  입력 데이터의 형태가 정해져 있고, 출력 역시 알고리즘에 의해 정해져 있다. 경우의 수가 매우 많은 프로그램(*바둑, 장기, 체스 등/ 이메일 스팸 필터*)의 경우, 이러한 Explicit Programming으로 해결할 수 없다. 



* 등장 : Samuel Arthur

 1959년, Samuel Arthur가 데이터를 기반으로 배우는 능력을 가진(학습할 수 있는) 프로그램을 만들었다. 고정된 프로그램이 아니라, 스스로 학습을 통해 변화하는 프로그램이다. 



* 학습(Learning)의 종류

  

1. 지도학습(Supervised Learning)

   * 학습의 목적: model 형성.

   * 학습용 데이터(Training Data Set) 존재. 라벨이 붙어 있음.

     > 예) 오리그림 1 = 오리, 오리그림 2(오리그림1과는 다름) = 오리, 너구리그림 1 = 너구리, 기린그림 1 = 오리, ...

     

   * 예측 모델 형성: 학습 진행 후, prediction model을 만듦.  

* 다른 데이터를 모델에 입력하면, 결과 출력.

  *예) 오리그림 3을 넣었을 때 오리를 출력.*

* 지도학습을 위해 필요한 통계적 model이 **회귀분석** 모형.

* 지도학습의 유형

  * 1) 선형회귀

    Training Data Set의 종속변수의 값이 various.

    >  `x(시간)`					`y(점수)`          *예) 7시간 공부하면 몇 점이 나올까?*
    >
    > ​	 1								 5
    >
    > ​     2								15
    >
    > ​     5  							  68
    >
    > ​     8								80
    >
    > ​	10							  95

  * 2) 로지스틱회귀(Logistic Regression): Binary Classification

    Training Data Set의 종속변수의 값(label)이 0(`True`) 혹은 1(`False`)로, 두 가지 종류.

    > `x(시간)`					`y(점수)`		  *예) 몇 시간 공부해야 합격할까?*
    >
    > ​	 1							  Fail
    >
    > ​     2							  Fail
    >
    > ​     5  							Fail
    >
    > ​     8							 Pass
    >
    > ​	10							Pass  

  * 3) Multinomial Classification

    Training Data Set의 종속변수의 값(label)이 여러 종류.

    > `x(시간)`					`y(점수)`		  *예) 7시간 공부했을 때 학점은 뭐냐?*
    >
    > ​	 1							   F
    >
    > ​     2							   F
    >
    > ​     5  							 C
    >
    > ​     8							   B
    >
    > ​	10							  A  



* 2. 비지도학습(Unsupervised Learning)

  * 학습의 목적: clustering(유사 집단으로의 분류).

    * 학습용 데이터(Training Data Set) 존재.

    * Label은 존재하지 않음.

      *예) 오리그림1, 오리그림2, 토끼그림1, 고슴도치그림1, ... => 뒤에 각각이 어떤 그림인지 label 없이 그림들만 입력*

    * **클러스터링(Clustering)** 기법: 학습 진행 후, 유사한 집단으로 분류.

      *예) 오리그림1, 오리그림2 / 토끼그림1 / 고슴도치그림1 / ...*

      *예) 뉴스 기사 읽고 분석해서 자동으로 분리*

* 3. 강화학습

* ...등등...

* 머신러닝의 응용

  * 이미지 검색.
  * 도난 신용카드 판별 : 소비 패턴, boundary 등을 벗어났을 때.
  * 예상 매출액 산출.



### 2.2. 선형회귀(Linear Regression)



#### 2.2.1. 선형회귀 모형 개념

* 학습용 데이터: Label을 결정하기 위해 변수가 1개일 수도 있고, 그 이상일 수도 있음.
  * 단순회귀분석 : 변수가 1개.
  * 다중회귀분석: 변수가 2개 이상.

* 일반적으로 많은 현상(data)가 선형(linear)의 형태를 가짐.

  *예) 공부 시간이 많아질수록 시험 성적이 높아진다.*

  *예) 근로 시간이 길수록 급여가 많아진다.*

  *예) 공을 세게 던질수록 나가는 거리가 길어진다.*

  *예) 배달 지역이 멀수록 배달 소요 시간이 길어진다.*

* **임의로** 그 데이터를 가장 잘 설명할 수 있는 선형 형태의 가설(선형의 추정식)을 설정한다.

* **학습 : (데이터를 더 적합하게 설명할 수 있도록) 가설(=식)을 수정해 나가는 과정.**

* **모델 설정 : 반복적인 학습을 통해 가설을 계속 수정하고, 데이터에 *가장 근접한 회귀식*을 도출함.**

* 가설은 직선, 곡선, 면 등 모든 형태로 나올 수 있음.



#### 2.2.2. 최소제곱법: 선형회귀 모델의 학습 방식

> 선형회귀 모델을 적용해 가설을 수정해 나갈 때, 최소제곱법 방식 이용.
>
> **가설과 데이터 간 간격의 제곱의 평균**을 구해서, 그 값이 작을수록 더 좋은 가설.

* 가설 설정 : 데이터와 회귀식 간의 차이를 구하고, 그 차이의 제곱합의 평균이 최소가 되도록 가설 설정.

  * 제곱합 이용 : 편차의 합은 부호 문제로 인해 정확하지 않음.
  * 최소제곱합은 그 정의에 따라, 반드시 0 이상.

* 일반식: 비용함수(Cost Function/Loss Function) => 가설을 최적화하기 위해 최소화시켜야 하는 ***목적함수!!!***

  * 단일변수 : `H(x) = Wx + b`
  * 변수 2개 이상 : `H(x1, x2) = W1x1 + W2x2 + b`

* 최소제곱합이 작을수록 좋은 회귀식.

* **목표 : 비용함수가 최소가 되는 계수와 절편을 구하는 것.**

* *예시 : linear 형태를 가진다고 가정하는 data set*

  * *3개의 학습 데이터*

  |  X   | Y(Label) |
  | :--: | :------: |
  |  1   |    1     |
  |  2   |    2     |
  |  3   |    3     |
  | ...  |   ...    |

  * 가설(hypothesis): `H = Wx + b`(`w`: 가중치, `b`: 절편(intercept)

    * 학습이 진행될수록 가설이 수정된다는 것은,
    * 가중치와 절편이 변화한다는 의미.
    * `w`와 `b`가 처음에는 random으로 주어지다가 점차 학습을 통해 변화함.

  * `H(x) = Wx + b`
     $$
     \frac {H(x_1-y_1)^2+H(x_2-y_2)^2+H(x_3-y_3)^2}{3} 
     $$
  
* 비용함수(Cost Function) 
  
  `C(W,b) =`
  
   ![1223_1](images/1223_1.jpg)
  
* 최적화 : 비용함수가 최소가 되는 `W`, `b`를 구하는 것.
  * 특정 `w`값에 대해 비용함수 미분.
  * 학습률(learning rate) : 최적화를 위해 **기울기**를 변화시켜나가는 정도

#### 2.2.3. 선형회귀모델의 프로그래밍

> 라이브러리의 도움을 받아 가설, 미분 등의 과정을 수행한다.

* skikit-learn
* tensor-flow
* ...

